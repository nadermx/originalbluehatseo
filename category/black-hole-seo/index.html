<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"> <html xmlns="http://www.w3.org/1999/xhtml"> <head profile="http://gmpg.org/xfn/1">   <script type="text/javascript" src="/static/js/analytics.js"></script> <script type="text/javascript">archive_analytics.values.server_name="wwwb-app12.us.archive.org";archive_analytics.values.server_ms=154;</script> <link type="text/css" rel="stylesheet" href="/static/css/banner-styles.css"/>   <link rel="icon" href="/favicon.ico" type="image/x-icon">  	<title>Blue Hat SEO-Advanced SEO Tactics &raquo; Black Hole SEO</title> 	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /> 	<meta name="generator" content="WordPress 2.0.7" /> <!-- leave this for stats please --> 	<style type="text/css" media="screen"> 		@import url(../../wp-content/themes/fasttrack/style.css); 	</style> 	<link rel="alternate" type="application/rss+xml" title="RSS 2.0" /> 	<link rel="alternate" type="text/xml" title="RSS .92" /> 	<link rel="alternate" type="application/atom+xml" title="Atom 0.3" /> 	<link rel="pingback" />     	<link rel='archives' title='June 2011' /> 	<link rel='archives' title='July 2010' /> 	<link rel='archives' title='June 2010' /> 	<link rel='archives' title='November 2009' /> 	<link rel='archives' title='September 2009' /> 	<link rel='archives' title='June 2009' /> 	<link rel='archives' title='April 2009' /> 	<link rel='archives' title='February 2009' /> 	<link rel='archives' title='November 2008' /> 	<link rel='archives' title='September 2008' /> 	<link rel='archives' title='August 2008' /> 	<link rel='archives' title='July 2008' /> 	<link rel='archives' title='May 2008' /> 	<link rel='archives' title='March 2008' /> 	<link rel='archives' title='December 2007' /> 	<link rel='archives' title='October 2007' /> 	<link rel='archives' title='September 2007' /> 	<link rel='archives' title='August 2007' /> 	<link rel='archives' title='July 2007' /> 	<link rel='archives' title='June 2007' /> 	<link rel='archives' title='May 2007' /> 	<link rel='archives' title='April 2007' /> 	<link rel='archives' title='March 2007' /> 	<link rel='archives' title='February 2007' /> 	<link rel='archives' title='January 2007' /> 	<link rel='archives' title='December 2006' /> 	<link rel='archives' title='November 2006' /> 	<link rel='archives' title='October 2006' /> 	<link rel='archives' title='September 2006' /> 	<link rel='archives' title='August 2006' /> 	<link rel='archives' title='July 2006' /> 	<link rel='archives' title='June 2006' /> 	<link rel='archives' title='May 2006' /> 	<link rel='archives' title='April 2006' /> 	<link rel='archives' title='March 2006' /> 	<link rel='archives' title='February 2006' /> 	<link rel='archives' title='January 2006' /> 	 <!-- tdomf: no posts to fix! -->  <script>   <!--    		// remote scripting library 		// (c) copyright 2005 modernmethod, inc 		var sajax_debug_mode = false; 		var sajax_request_type = "GET"; 		var sajax_target_id = ""; 		var sajax_failure_redirect = "";  		function sajax_debug(text) { 			if (sajax_debug_mode) 				alert(text); 		}   		function sajax_init_object() {  			sajax_debug("sajax_init_object() called..")   			var A;   			var msxmlhttp = new Array( 				'Msxml2.XMLHTTP.5.0', 				'Msxml2.XMLHTTP.4.0', 				'Msxml2.XMLHTTP.3.0', 				'Msxml2.XMLHTTP', 				'Microsoft.XMLHTTP'); 			for (var i = 0; i < msxmlhttp.length; i++) { 				try { 					A = new ActiveXObject(msxmlhttp[i]); 				} catch (e) { 					A = null; 				} 			}  			if(!A && typeof XMLHttpRequest != "undefined") 				A = new XMLHttpRequest(); 			if (!A) 				sajax_debug("Could not create connection object."); 			return A; 		}  		var sajax_requests = new Array();  		function sajax_cancel() { 			for (var i = 0; i < sajax_requests.length; i++) 				sajax_requests[i].abort(); 		}  		function sajax_do_call(func_name, args) { 			var i, x, n; 			var uri; 			var post_data; 			var target_id;  			sajax_debug("in sajax_do_call().." + sajax_request_type + "/" + sajax_target_id); 			target_id = sajax_target_id; 			if (typeof(sajax_request_type) == "undefined" || sajax_request_type == "") 				sajax_request_type = "GET";  			uri = "/category/black-hole-seo"; 			if (sajax_request_type == "GET") {  				if (uri.indexOf("?") == -1) 					uri += "?rs=" + escape(func_name); 				else 					uri += "&rs=" + escape(func_name); 				uri += "&rst=" + escape(sajax_target_id); 				uri += "&rsrnd=" + new Date().getTime();  				for (i = 0; i < args.length-1; i++) 					uri += "&rsargs[]=" + escape(args[i]);  				post_data = null; 			} 			else if (sajax_request_type == "POST") { 				post_data = "rs=" + escape(func_name); 				post_data += "&rst=" + escape(sajax_target_id); 				post_data += "&rsrnd=" + new Date().getTime();  				for (i = 0; i < args.length-1; i++) 					post_data = post_data + "&rsargs[]=" + escape(args[i]); 			} 			else { 				alert("Illegal request type: " + sajax_request_type); 			}  			x = sajax_init_object(); 			if (x == null) { 				if (sajax_failure_redirect != "") { 					location.href = sajax_failure_redirect; 					return false; 				} else { 					sajax_debug("NULL sajax object for user agent:\n" + navigator.userAgent); 					return false; 				} 			} else { 				x.open(sajax_request_type, uri, true); 				// window.open(uri);  				sajax_requests[sajax_requests.length] = x;  				if (sajax_request_type == "POST") { 					x.setRequestHeader("Method", "POST " + uri + " HTTP/1.1"); 					x.setRequestHeader("Content-Type", "application/x-www-form-urlencoded"); 				}  				x.onreadystatechange = function() { 					if (x.readyState != 4) 						return;  					sajax_debug("received " + x.responseText);  					var status; 					var data; 					var txt = x.responseText.replace(/^\s*|\s*$/g,""); 					status = txt.charAt(0); 					data = txt.substring(2);  					if (status == "") { 						// let's just assume this is a pre-response bailout and let it slide for now 					} else if (status == "-") 						alert("Error: " + data); 					else { 						if (target_id != "") 							document.getElementById(target_id).innerHTML = eval(data); 						else { 							try { 								var callback; 								var extra_data = false; 								if (typeof args[args.length-1] == "object") { 									callback = args[args.length-1].callback; 									extra_data = args[args.length-1].extra_data; 								} else { 									callback = args[args.length-1]; 								} 								callback(eval(data), extra_data); 							} catch (e) { 								sajax_debug("Caught error " + e + ": Could not eval " + data ); 							} 						} 					} 				} 			}  			sajax_debug(func_name + " uri = " + uri + "/post = " + post_data); 			x.send(post_data); 			sajax_debug(func_name + " waiting.."); 			delete x; 			return true; 		}  		 		// wrapper for tdomf_ajax_send_post 		function x_tdomf_ajax_send_post() { 			sajax_do_call("tdomf_ajax_send_post", 				x_tdomf_ajax_send_post.arguments); 		}  		  // DHTML email validation script. Courtesy of SmartWebby.com (/web/20130508093228/http://www.smartwebby.com/dhtml/)   function echeck(str) {     var at="@"     var dot="."     var lat=str.indexOf(at)     var lstr=str.length 		var ldot=str.indexOf(dot) 		if (str.indexOf(at)==-1){ 		   //alert("Invalid E-mail ID") 		   return false 		} 		if (str.indexOf(at)==-1 || str.indexOf(at)==0 || str.indexOf(at)==lstr){ 		   //alert("Invalid E-mail ID") 		   return false 		} 		if (str.indexOf(dot)==-1 || str.indexOf(dot)==0 || str.indexOf(dot)==lstr){ 		    //alert("Invalid E-mail ID") 		    return false 		} 		 if (str.indexOf(at,(lat+1))!=-1){ 		    //alert("Invalid E-mail ID") 		    return false 		 } 		 if (str.substring(lat-1,lat)==dot || str.substring(lat+1,lat+2)==dot){ 		    //alert("Invalid E-mail ID") 		    return false 		 } 		 if (str.indexOf(dot,(lat+2))==-1){ 		    //alert("Invalid E-mail ID") 		    return false 		 } 		 if (str.indexOf(" ")!=-1){ 		    //alert("Invalid E-mail ID") 		    return false 		 }      return true					   }    -->   </script>   <script>   <!--   function tdomf_clear_form() {     document.getElementById("tdomf_form1_title").value = "";     document.getElementById("tdomf_form1_content").value = "";     var e1 = document.getElementById("tdomf_form1_notify");     if(e1 != null) { e1.checked = true; }     var e2 = document.getElementById("tdomf_form1_email");     if(e2 != null) { e2.value = ""; }     var e3 = document.getElementById("tdomf_form1_name");     if(e3 != null) { e3.value = ""; }     document.getElementById("tdomf_form1_msg_div").innerHTML = "";     document.getElementById("tdomf_form1_div").style.display = 'block';   }   function tdomf_send_form_cb(message) {     document.getElementById("tdomf_form1_msg_div").innerHTML = message;   }   function tdomf_send_form() {     var message = document.getElementById("tdomf_form1_msg_div");          var title = document.getElementById("tdomf_form1_title").value;     var content = document.getElementById("tdomf_form1_content").value;      var error = "";     if(title.length == 0){ error += "You must specify a title.<br/>"; }     if(content.length == 0){ error += "You must add some text.<br/>"; }          var name = "";     var e1 = document.getElementById("tdomf_form1_name");     if(e1 != null){        name = e1.value;        if(name.length == 0){          error += "You must specify a name so we know who it comes from.<br/>";        }     }     var email = "";     var e2 = document.getElementById("tdomf_form1_email");     if(e2 != null){        email = e2.value;        if(echeck(email) == false){          error += "The email you specified is invalid.<br/>";        }     }          var web = "";     var e3 = document.getElementById("tdomf_form1_web");     if(e3 != null){       web = e3.value;     }          var notify = false;     var e3 = document.getElementById("tdomf_form1_notify");     if(e3 != null){ notify = e3.checked; }          if(error.length > 0) {       message.innerHTML = '<font color="red">' + error + '</font>';     } else {       var theform = document.getElementById("tdomf_form1_div");       theform.style.display = 'none';       message.innerHTML = '<center><img src="/web/20130508093228/http://www.bluehatseo.com/wp-content/plugins/TDOMiniForms/ajax-loader.gif" /></center>';       x_tdomf_ajax_send_post(title, content, notify, email, name, web, tdomf_send_form_cb);     }   }   -->   </script> <script language="javascript" type="text/javascript"> <!-- 		function collapseThread( theId ) { 			var comment = document.getElementById(theId); 			if(!comment) 			{ 				alert("ERROR:\nThe document structure is different\nfrom what Threaded Comments expects.\nYou are missing the element '"+theId+"'"); 				return; 			} 			var theBody = findBody(comment); 			if(comment.className.indexOf("collapsed") > -1) { 				comment.className = comment.className.replace(" collapsed", "");; 			} else { 				comment.className += " collapsed"; 			} 		}  		function expandThread( theId ) { 			var comment = document.getElementById(theId); 			if(!comment) 			{ 				alert("ERROR:\nThe document structure is different\nfrom what Threaded Comments expects.\nYou are missing the element '"+theId+"'"); 				return; 			} 			var theBody = findBody(comment); 			if(comment.className.indexOf("collapsed") > -1) { 				comment.className = comment.className.replace(" collapsed", "");; 			}  		} 		 		function findBody(el) 		{ 			var divs = el.getElementsByTagName("div"); 			var ret; 			for(var i = 0; i < divs.length; ++i) { 				if(divs.item(i).className.indexOf("body") > -1) 					return divs.item(i); 			} 			return false; 		} 	 		function onAddComment() { 			//checkDocumentIntegrity(); 			var el = document.getElementById("commentform"); 			// Future release: Check if form is filled correctly and mark the form fields. 			el.submit(); 		} 		 		function moveAddCommentBelow(theId, threadId, collapse) 		{ 			expandThread( theId ); 			var addComment = document.getElementById("addcomment"); 			if(!addComment) 			{ 			  	alert("ERROR:\nThreaded Comments can't find the 'addcomment' div.\nThis is probably because you have changed\nthe comments.php file.\nMake sure there is a tag around the form\nthat has the id 'addcomment'");  				return 			} 			var comment = document.getElementById(theId); 			if(collapse) 			{ 				for(var i = 0; i < comment.childNodes.length; ++i) { 					var c = comment.childNodes.item(i); 					if(typeof(c.className) == "string" && c.className.indexOf("collapsed")<0) { 						c.className += " collapsed"; 					} 				} 			} 			addComment.parentNode.removeChild(addComment);  			comment.appendChild(addComment); 			if(comment.className.indexOf("alt")>-1) { 				addComment.className = addComment.className.replace(" alt", "");					 			} else { 				addComment.className += " alt"; 			} 		        var replyId = document.getElementById("comment_reply_ID"); 			if(replyId == null) 			{ 				alert("Brians Threaded Comments Error:\nThere is no hidden form field called\n'comment_reply_ID'. This is probably because you\nchanged the comments.php file and forgot\nto include the field. Please take a look\nat the original comments.php and copy the\nform field over."); 			} 			replyId.value = threadId; 			var reRootElement = document.getElementById("reroot"); 			if(reRootElement == null) 			{ 				alert("Brians Threaded Comments Error:\nThere is no anchor tag called 'reroot' where\nthe comment form starts.\nPlease compare your comments.php to the original\ncomments.php and copy the reroot anchor tag over."); 			} 			reRootElement.style.display = "block"; 			var aTags = comment.getElementsByTagName("A"); 			var anc = aTags.item(0).id; 			//document.location.href = "#"+anc; 			document.getElementById("comment").focus(); 		}  		function checkDocumentIntegrity() 		{ 			str = ""; 			 			str += checkElement("reroot","div tag"); 			str += checkElement("addcomment", "div tag"); 			str += checkElement("comment_reply_ID", "hidden form field"); 			str += checkElement("content", "div tag"); 			str += checkElement("comment", "textfield"); 			str += checkElement("addcommentanchor", "anchor tag"); 			 			if(str != "") 			{ 				str = "Brian's Threaded Comments are missing some of the elements that are required for it to function correctly.\nThis is probably the because you have changed the original comments.php that was included with the plugin.\n\nThese are the errors:\n" + str; 				str += "\nYou should compare your comments.php with the original comments.php and make sure the required elements have not been removed.";  				alert(str); 			} 		}                 		function checkElement(theId, elDesc) 		{ 			var el = document.getElementById(theId); 			if(!el) 			{ 				if(elDesc == null) 					elDesc = "element"; 				return "- The "+elDesc+" with the ID '" +theId + "' is missing\n";  			} 			else  				return ""; 		} 		 		function reRoot() 		{ 			var addComment = document.getElementById("addcomment");			 			var reRootElement = document.getElementById("reroot"); 			reRootElement.style.display = "none"; 			var content = document.getElementById("content"); 			addComment.parentNode.removeChild(addComment); 			content.appendChild(addComment); 			addComment.className = addComment.className.replace(" alt", ""); 			document.location.href = "#addcommentanchor"; 			document.getElementById("comment").focus();				 			document.getElementById("comment_reply_ID").value = "0"; 		}			 		 		function changeCommentSize(d) 		{ 			var el = document.getElementById("comment"); 			var height = parseInt(el.style.height); 			if(!height && el.offsetHeight) 				height = el.offsetHeight; 			height += d; 			if(height < 20)  				height = 20; 			el.style.height = height+"px"; 		}		 --> </script> <style type="text/css"> .comment  { 	position: 				relative; 	margin:					3px; 	margin-top:				6px; /*	border: 				1px solid #666; */ 	padding:				4px 4px 4px 8px; 	font-size:				98%; 	background-color:		#fff; }  .odd { 	background-color: #f8f8f8; }  .comment div { 	position: 				relative; }  .comment .comment img { 	margin: 				0px; }  .comment .collapseicon  { 	width: 					13px; 	height: 				13px; 	overflow:				hidden; 	background-image: 		url(../../wp-content/plugins/briansthreadedcomments.php?image=subthread-open.png); }  .collapsed .collapseicon  { 	background-image: 		url(../../wp-content/plugins/briansthreadedcomments.php?image=subthread.png); }   .comment .reply { 	text-align: 			right; 	font-size: 				80%; 	padding: 				0px 6px 6px 0px; }  .comment { 	border: 	1px solid #ddd; 	margin-top: 			10px; }  input#subscribe { 	width: auto; }  .comment .body .content { 	padding:				0px 3px 0px 3px; 	width: 					100%;	 	overflow: 				auto;  }  .comment .title abbr { 	border: none; }  .collapsed .body, .collapsed .comment { 	display:				none; } /* #addcomment small, #addcomment div { 	padding:				3px; } */ #commentform textarea { 	width: 97%; } </style> </head>  <body id="archives">    <script type="text/javascript" src="/static/js/disclaim-element.js" ></script> <script type="text/javascript" src="/static/js/graph-calc.js" ></script> <script type="text/javascript">//<![CDATA[ var __wm = (function(imgWidth,imgHeight,yearImgWidth,monthImgWidth){ var wbPrefix = "/web/"; var wbCurrentUrl = "http://www.bluehatseo.com/category/black-hole-seo";  var firstYear = 1996; var displayDay = "8"; var displayMonth = "May"; var displayYear = "2013"; var prettyMonths = ["Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec"]; var $D=document,$=function(n){return document.getElementById(n)}; var trackerVal,curYear = -1,curMonth = -1; var yearTracker,monthTracker; function showTrackers(val) {   if (val===trackerVal) return;   var $ipp=$("wm-ipp");   var $y=$("displayYearEl"),$m=$("displayMonthEl"),$d=$("displayDayEl");   if (val) {     $ipp.className="hi";   } else {     $ipp.className="";     $y.innerHTML=displayYear;$m.innerHTML=displayMonth;$d.innerHTML=displayDay;   }   yearTracker.style.display=val?"inline":"none";   monthTracker.style.display=val?"inline":"none";   trackerVal = val; } function trackMouseMove(event,element) {   var eventX = getEventX(event);   var elementX = getElementX(element);   var xOff = Math.min(Math.max(0, eventX - elementX),imgWidth);   var monthOff = xOff % yearImgWidth;    var year = Math.floor(xOff / yearImgWidth);   var monthOfYear = Math.min(11,Math.floor(monthOff / monthImgWidth));   // 1 extra border pixel at the left edge of the year:   var month = (year * 12) + monthOfYear;   var day = monthOff % 2==1?15:1;   var dateString = zeroPad(year + firstYear) + zeroPad(monthOfYear+1,2) +     zeroPad(day,2) + "000000";    $("displayYearEl").innerHTML=year+firstYear;   $("displayMonthEl").innerHTML=prettyMonths[monthOfYear];   // looks too jarring when it changes..   //$("displayDayEl").innerHTML=zeroPad(day,2);   var url = wbPrefix + dateString + '/' +  wbCurrentUrl;   $("wm-graph-anchor").href=url;    if(curYear != year) {     var yrOff = year * yearImgWidth;     yearTracker.style.left = yrOff + "px";     curYear = year;   }   if(curMonth != month) {     var mtOff = year + (month * monthImgWidth) + 1;     monthTracker.style.left = mtOff + "px";     curMonth = month;   } } function hideToolbar() {   $("wm-ipp").style.display="none"; } function bootstrap() {   var $spk=$("wm-ipp-sparkline");   yearTracker=$D.createElement('div');   yearTracker.className='yt';   with(yearTracker.style){     display='none';width=yearImgWidth+"px";height=imgHeight+"px";   }   monthTracker=$D.createElement('div');   monthTracker.className='mt';   with(monthTracker.style){     display='none';width=monthImgWidth+"px";height=imgHeight+"px";   }   $spk.appendChild(yearTracker);   $spk.appendChild(monthTracker);    var $ipp=$("wm-ipp");   $ipp&&disclaimElement($ipp); } return{st:showTrackers,mv:trackMouseMove,h:hideToolbar,bt:bootstrap}; })(550, 27, 25, 2);//]]> </script> </style> <div id="wm-ipp" lang="en" style="display:none;"></div> </script>   <div id="rap"> 	<div id="header"> 	<h1><a href="/" title="Blue Hat SEO-Advanced SEO Tactics" style="color:#177efd;">Blue Hat SEO-Advanced SEO Tactics</a></h1> </div> 	 	<div id="content"> 					<h3>Black Hole SEO</h3> 			<div class="post-info">Archived Posts from this Category</div>		 			<br/>				 							 				<div class="post"> 					<div class="post-title"><em><a href="/category/black-hole-seo/" title="View all posts in Black Hole SEO" rel="category tag">Black Hole SEO</a></em>18 Jun 2007 09:53 pm</div> <p class="post-info"><a href="/black-hole-seo-the-real-desert-scraping/" rel="bookmark" title="Permanent Link: Black Hole SEO: The Real Desert Scraping"><b>Black Hole SEO: The Real Desert Scraping</b></a></p> <div class="post-content" align="justified"> 	<p>Alright fine. I&#8217;m going to call uncle on this one. With my last Black Hole SEO post I talked about <a href="/black-hole-seo-desert-scraping/">Desert Scraping</a>. Now understand, I usually change up my techniques and remove a spin or two before I make them public as to not hurt my own use of it. However on this one, in the process, I totally dumbed it down. Upon retrospect it definitely doesn&#8217;t qualify as a Black Hole SEO technique, more like a general article, and yet no one called me on it! Com&#8217;n guys you&#8217;re starting to slip. <img src='/wp-includes/images/smilies/icon_smile.gif' alt=':)' class='wp-smiley' />  Enough of this common sense shit, lets do some real black hat.  So the deal is I&#8217;m going to talk about desert scraping one more time and this time just be perfectly candid and disclose the actual spin I use on the technique.</p> <p><strong>The Real Way To Desert Scrape</strong><br /> <strong>1.</strong> Buy a domain name and setup Catch-All subdomains on it using Mod-Rewrite and the Apache config.</p> <p><strong>2.</strong> Write a simple script where you can pull content from a database and spit it out on it&#8217;s own subdomain. No general template required.</p> <p><strong>3.</strong> Setup a main page on the domain that points links to the newest subdomains along with their titles to help them get indexed.</p> <p><strong>4.</strong> Signup for a service that monitors expiring domains such as <a href="http://www.deleteddomains.com/today_deletions.php" target="_new">DeletedDomains.com</a> (just a suggested one, there&#8217;s plenty much better ones out there).</p> <p><strong>5.</strong> On a cronjob everyday have it scan the newest list of domains that were deleted that day. Store the list in a temporary table in the database.</p> <p><strong>6.</strong> On a second cronjob continuously ran throughout the day have it lookup each expired domain using Archive.org. have it do a deep crawl and replace any links to their local equivalents (ie. www.expireddomain.com/page2.html becomes /page2.html). Do the same with the images used in the template.</p> <p><strong>7.</strong> Create a simple algorithm to replace all known ads you can find and think of with your own, such as Adsense. Also it doesn&#8217;t hurt to replace any outgoing links with other sites of yours that are in need of some link popularity.</p> <p><strong>8.</strong> Put the scraped site up on a subdomain using the old domain minus the tld. So if the site was mortgageloans.com your subdomain would be mortgageloans.mydomain.com.</p> <p><strong>9.</strong> Have the cronjob add the new subdomain up on the list of completed ones so it can be listed on the main page and indexed.</p> <p><strong>What Did This Do?</strong><br /> Now you got a site that grows in unique content and niche coverage. Everyday new content goes up and new niches are created on that domain. By the time each subdomain gets fully indexed much of the old pages on the expired domains will start falling from the index. Ideally you&#8217;ll create a near perfect replacement with very little duplicate content problems. Over time your site will start to get huge and start drawing BIG ad revenue. So all you have to do is start creating more of these sites.  Since there are easily in the six figures of domains expiring everyday that is obviously too much content for any single domain, so building these sites in a network is almost required. So be sure to preplan the load possible balancing during your coding. The fewer scraped sites each domain has to put up a day the better chances of it all getting properly indexed and ranking.</p> <p>And THAT is how you Desert Scrape the Eli way. <img src='/wp-includes/images/smilies/icon_smile.gif' alt=':)' class='wp-smiley' /> </p> <p><em>*Wink* I may just have hinted at an unique Black Hole SEO way of finding high profit and easy to conquer niches. How about exploiting natural traffic demand generated by article branding?</em> </p>  	<p class="post-info"> 													 	</p> 	<!-- 		<rdf:RDF xmlns:rdf="/web/20130508093228/http://www.w3.org/1999/02/22-rdf-syntax-ns#" 	    xmlns:dc="/web/20130508093228/http://purl.org/dc/elements/1.1/" 	    xmlns:trackback="/web/20130508093228/http://madskills.com/public/xml/rss/module/trackback/"> 		<rdf:Description rdf:about="/web/20130508093228/http://www.bluehatseo.com/black-hole-seo-the-real-desert-scraping/"     dc:identifier="/web/20130508093228/http://www.bluehatseo.com/black-hole-seo-the-real-desert-scraping/"     dc:title="Black Hole SEO: The Real Desert Scraping"     trackback:ping="/web/20130508093228/http://www.bluehatseo.com/black-hole-seo-the-real-desert-scraping/trackback/" /> </rdf:RDF>	--> </div> <div class="post-footer"><a href="/black-hole-seo-the-real-desert-scraping/#comments" title="Comment on Black Hole SEO: The Real Desert Scraping">210 Comments &#187;</a></div>									</div> 							 				<div class="post"> 					<div class="post-title"><em><a href="/category/black-hole-seo/" title="View all posts in Black Hole SEO" rel="category tag">Black Hole SEO</a></em>16 Jun 2007 02:00 pm</div> <p class="post-info"><a href="/black-hole-seo-desert-scraping/" rel="bookmark" title="Permanent Link: Black Hole SEO: Desert Scraping"><b>Black Hole SEO: Desert Scraping</b></a></p> <div class="post-content" align="justified"> 	<p>In my introduction post to <a href="/follow-up-to-100s-of-automated-linkshour-post/">Black Hole SEO</a> I hinted that I was going to talk about how to get &#8220;unique authoritative content.&#8221; I realize that sounds like an oxymoron. If content is authoritative than that means it must be proven to work well in the search engines. Yet if the content is unique than it can&#8217;t exist in the search engines. Kind of a nasty catch-22. So how is unique authoritative content even possible? Well to put it simply, content can be dropped from the search engines&#8217; index.</p> <p>That struck a cord didn&#8217;t it? So if content can be in the search engines one day and be performing very well and months to years down the road no longer be listed, than all we have to do is find it and snag it up. That makes it both authoritative and as of the current moment, unique as well.  This is called Desert Scraping because you find deserted and abandoned content and claim it as your own. Well, there&#8217;s quite a few ways of doing it of course. Most of which is not only easy to do but can be done manually by hand so they don&#8217;t even require any special scripting. Let&#8217;s run through a few of my favorites.</p> <p><strong>Archive.org</strong><br /> Alexa&#8217;s Archive.org is one of the absolute best spots to find abandoned content. You can look up any old authoritative articles site and literally find thousands of articles that once performed in the top class yet no longer exist in the engines now. Let&#8217;s take into example one of the great classic authority sites, Looksmart.</p> <p><strong>1. Go to Archive.org and search for the authority site you&#8217;re wanting to scrape.</strong><br /> <img id="image228" src="/wp-content/uploads/2007/06/archive1.JPG" alt="archive1.JPG" /></p> <p><strong>2. Select an old date, so the articles will have plenty of time to disappear from the engines.</strong><br /> <img id="image229" src="/wp-content/uploads/2007/06/archive2.JPG" alt="archive2.JPG" /></p> <p><strong>3. Browse through a few subpages till you find an article on your subject that you would like to have on your site.</strong><br /> <img id="image230" src="/wp-content/uploads/2007/06/looksmart1.JPG" alt="looksmart1.JPG" /></p> <p><strong>4. Find an article that fits your subject perfectly.</strong><br /> <img id="image231" src="/wp-content/uploads/2007/06/looksmart2.jpg" alt="looksmart2.jpg" /></p> <p><strong>5. Do a SITE: command in the search engines to see if the article still exists there.</strong><br /> <img id="image232" src="/wp-content/uploads/2007/06/exists.jpg" alt="exists.jpg" /></p> <p><strong>6. If it no longer exists just copy the article and stake your claim. <img src='/wp-includes/images/smilies/icon_smile.gif' alt=':)' class='wp-smiley' /> </strong><br /> <img id="image233" src="/wp-content/uploads/2007/06/copy.jpg" alt="copy.jpg" /></p> <p>See how easy it is? This can be done for just about any old authority site. As you can imagine there&#8217;s quite a bit of content out there that is open for hunting. Just remember to focus on articles on sites that performed very well in the past, that ensures a much higher possibility of it performing well now. However, let&#8217;s say we wanted to do this on a mass scale without Archive.org. We already know that the search engines don&#8217;t index each and every page no matter how big the site is. So all we have to do is find a sitemap. <img src='/wp-includes/images/smilies/icon_smile.gif' alt=':)' class='wp-smiley' /> </p> <p><strong>Sitemaps</strong><br /> If you can locate a sitemap than you can easily make a list of all the pages on a domain. If you can get all the pages on the domain and compare them to the SITE: command in the search engines than you can return a list of all the pages/articles that aren&#8217;t indexed.</p> <p>1. Locate the sitemap on the domain and parse it into a flat file with just the urls.</p> <p>2. Make a quick script to go through the list and do a SITE: command for each URL in the search engines.</p> <p>3. Anytime the search engine returns a result total of greater than 0, just delete the url off the list.</p> <p>4. Verify the list by making sure that each url actually does exist and consists of articles you would like to use.</p> <p>There is one inherent problem with the automatic way. Since it&#8217;s grabbing the entire site through its sitemap than you are going to get a ton of negative results, like search queries and other stuff they want indexed but you want no part of. So it&#8217;s best to target a particular subdirectory or subdomain within the main domain that fits your targeted subject matter. For instance if you were wanting articles on Automotive, than only use the portion of the sitemap that contains domain.com/autos or autos.domain.com.</p> <p>There are quite a few other methods of finding deserted content. For instance many big sites use custom 404 error pages. A nice exploit is to do <strong>site:domain.com &#8220;Sorry this page cannot be found&#8221;</strong> then lookup the cached copy in another search engine that may not of updated the page yet.  There is certainly no shortage of them. Can you think of any others?</p> <p>Cheers <img src='/wp-includes/images/smilies/icon_smile.gif' alt=':)' class='wp-smiley' /> </p>  	<p class="post-info"> 													 	</p> 	<!-- 		<rdf:RDF xmlns:rdf="/web/20130508093228/http://www.w3.org/1999/02/22-rdf-syntax-ns#" 	    xmlns:dc="/web/20130508093228/http://purl.org/dc/elements/1.1/" 	    xmlns:trackback="/web/20130508093228/http://madskills.com/public/xml/rss/module/trackback/"> 		<rdf:Description rdf:about="/web/20130508093228/http://www.bluehatseo.com/black-hole-seo-desert-scraping/"     dc:identifier="/web/20130508093228/http://www.bluehatseo.com/black-hole-seo-desert-scraping/"     dc:title="Black Hole SEO: Desert Scraping"     trackback:ping="/web/20130508093228/http://www.bluehatseo.com/black-hole-seo-desert-scraping/trackback/" /> </rdf:RDF>	--> </div> <div class="post-footer"><a href="/black-hole-seo-desert-scraping/#comments" title="Comment on Black Hole SEO: Desert Scraping">175 Comments &#187;</a></div>									</div> 							 				<div class="post"> 					<div class="post-title"><em><a href="/category/black-hole-seo/" title="View all posts in Black Hole SEO" rel="category tag">Black Hole SEO</a></em>06 May 2007 01:23 pm</div> <p class="post-info"><a href="/follow-up-to-100s-of-automated-linkshour-post/" rel="bookmark" title="Permanent Link: Follow Up To 100&#8217;s Of Automated Links/Hour Post"><b>Follow Up To 100&#8217;s Of Automated Links/Hour Post</b></a></p> <div class="post-content" align="justified"> 	<p><strong>This is a follow post to my <a href="/100s-of-linkshour-automated-introduction-to-black-hole-seo/">100&#8217;s Of Links/Hour Automated</a> - Black Hole SEO post.</strong></p> <p>I&#8217;m going to concede on this one. I admittedly missed a few explanations of some fundamentals that I think left a lot of people out of all the fun. After reading a few comments, emails and <a target="_blank" href="http://www.woodymaxim.com/cinco-de-mayo-is-gone-for-yet-another-year">inbound links</a> (thanks <a target="_blank" href="http://www.cucirca.com/2007/05/06/links-for-06-05-2007">Cucirca</a> &#038; <a target="_blank" href="http://www.yellowhousehosting.com/resources">YellowHouse</a> for good measure) I realize that unless you already have adequate experience building RSS Scraper Sites than its very tough to fully understand my explanation of how to exploit them. So I&#8217;m going to do a complete re-explanation and keep it completely nontechnical. This post will become the post to explain how it works, and the other will be the one to explain how to do it. Fair enough? Good, lets get started with an explanation of exactly what a RSS scraper site is. So once again, this time with a MGD in my hand, cheers to Seis De Mayo!</p> <p><strong>Fundamentals Of Scraping RSS</strong><br /> Most blogs automatically publish an RSS feed in either a XML or ATOM format. <a href="/feed/">Here&#8217;s mine</a> for an example. These feeds basically consist of a small snipplet of your post(usually the first 500 or so characters) as well as the Title of the post and the Source URL. This is so people can add your blog into their Feed Readers and be updated when new posts arrive. Sometimes people like to be notified on a global scale of posts related to a specific topic. So there are blog search engines that are a compilation of all the RSS feeds they know about through either their own scrapings of the web or people submitting them through their submission forms. They allow you to search through millions of RSS feeds by simply entering a keyword or two. An example of this might be to use Google Blog Search&#8217;s direct XML search for the word puppy. Here&#8217;s the <a target="_blank" href="http://blogsearch.google.com/blogsearch_feeds?hl=en&amp;q=puppy&amp;ie=utf-8&amp;num=10&amp;output=rss">link</a>. See how it resulted in a bunch of recent posts that included the word Puppy in either the title or the post content snippet (description). These are known as RSS Aggregators. The most popular of which would be, <a target="_blank" href="http://blogsearch.google.com/blogsearch_feeds?hl=en&amp;q=puppy&amp;ie=utf-8&amp;num=10&amp;output=rss">Google Blog Search</a>, <a href="http://news.search.yahoo.com/news/rss;_ylt=A9j8euxCOD5GZPEAIwvQtDMD;_ylu=X3oDMTA3MTBsZGZsBHNlYwNhZG0-?ei=UTF-8&amp;p=puppy&amp;eo=UTF-8">Yahoo News Search</a>, &#038; <a target="_blank" href="http://www.daypop.com/search?q=puppy&amp;s=1&amp;c=10&amp;ext=true&amp;t=w&amp;o=rss">Daypop</a>.</p> <p>So when a black hatter in an attempt to create a massive site based on a set of keywords needs lots and lots of content one of the easiest ways would be to scrape these RSS Aggregators and use the Post Titles and Descriptions as actual pages of content. This however is a defacto form of copyright infringement since they are taking little bits of random people&#8217;s posts. The post Title&#8217;s don&#8217;t matter because they can&#8217;t be copyrighted but the actual written text can be if the person chose to have description within their feed include the entire post rather than just a snippet of it. I know it&#8217;s bullshit how Google is allowed to republish the information but no one else is, but like i said its defacto. It only matters to the beholder(which is usually a bunch of idiotic bloggers who don&#8217;t know better). So to keep in the up and up the Black Hatters always be sure to include proper credit to the original source of the post by linking to the original post as indicated in the RSS feed they grabbed. This backlink slows down the amount of complaints they have to deal with and makes their operation legitimate enough to continue stress free. At this point they are actually helping the original bloggers by not only driving traffic to their sites but giving them a free backlink, Google becomes the only real victim(boohoo). So when the many many people who use public RSS Scraper scripts such as Blog Solution and RSSGM on a mass scale start producing these sites they mass scrape thousands of posts from typically the three major RSS Aggregators listed above. They just insert their keywords in place of my &#8220;puppy&#8221; and automatically publish all the posts that result.</p> <p>After that they need to get those individual pages indexed by the search engines. This is important because they want to start ranking for all these subkeywords that result from the post titles and within the post content. This results in huge traffic. Well not huge, but a small amount per RSS Scraper site they put up. This is usually done in mass scale over thousands of sites (also known as Splogs, spam blogs) which results in lots and lots of search engine traffic. They fill each page with ads (MFA, Made For Adsense Sites) and convert the click through rate on that traffic into money in their pockets. Some Black Hatters make this their entire profession. Some even create in the upwards of 5 figures worth of sites, each targeting different niches and keywords. One of the techniques they do to get these pages indexed quickly is to &#8220;ping&#8221; Blog Aggregators. Blog aggregators are nothing more than a rolling list of &#8220;recently updated blogs.&#8221; So they send a quick notification to these places by automatically filing out and submitting a form with the post title, and url to their new scraped page. A good example of the most common places they ping can be found in mass ping programs such as <a target="_blank" href="http://pingomatic.com">Ping-O-Matic</a>. The biggest of those would probably include <a target="_blank" href="http://www.weblogs.com">Weblogs</a>. They also will do things such as comment spam on blogs and other link bombing techniques to generate lots of deep inbound links to these sites so they can outrank all the other sites going for the niche the original posts included. This is a good explanation of why Weblogs.com is so worthless now. Black Hatters can supply these sites and generate thousands of RSS Scraped posts daily. Where legitimate bloggers can only do about one post every day or so. So these Blog Aggregator sites quickly get overrun and it can easily be assumed that about 90% of the posts that show up on there are actually pointed to and from RSS Scraper Sites. This is known as the <strong>Blog N&#8217; Ping</strong> method.</p> <p>I&#8217;m going to stop the explanation right there, because I keep saying &#8220;they&#8221; and it&#8217;s starting to bug me. Fuck guys I do this to! Haha. In fact most of the readers here do it as well. We already know tens of thousands, if not more, of these posts go up everyday and give links to whatever original source is specified in the RSS Aggregators. So all we got to do is figure out how to turn those links into OUR links. Now that you know what it is at least, lets learn how to exploit it to gain hundreds of automated links an hour.</p> <p><strong>What Do We Know So Far?</strong><br /> <strong> 1)</strong> We know where these Splogs (RSS Scraper sites) get their content. They get them from RSS Aggregators such as <a target="_blank" href="http://blogsearch.google.com">Google Blog Search</a>.</p> <p><strong>2)</strong> We know they post up the Title, Description (snippet of the original post) and a link to the Source URL on each individual page they make.</p> <p><strong>3)</strong> We know the majority of these new posts will eventually show up on popular Blog Aggregators such as Weblogs.com. We know these Blog Aggregators will post up the Title of the post and a link to the place it&#8217;s located on the Splogs.</p> <p><strong>4)</strong> We also know that somewhere within these post titles and/or descriptions are the real keywords they are targeting for their Splog.</p> <p><strong>5)</strong> Also, we know that if we republish these fake posts using these titles to the same RSS Aggregators the Black Hatters use eventually (usually within the same day) these Splogs will grab and republish our post on their sites.</p> <p><strong>6)</strong> Lastly, we know that if we put in our URL as the link to the original post the Splogs, once updated, will give us a backlink and probably post up just about any text we want them to.</p> <p>We now have the makings of some serious inbound link gathering. <img src='/wp-includes/images/smilies/icon_smile.gif' alt=':)' class='wp-smiley' /> </p> <p><strong>How To Get These Links</strong><br /> <strong> 1)</strong> First we&#8217;ll go to the Blog Aggregators and make a note of all the post titles they provide us. This is done through our own little <a href="/complete-guide-to-scraping-pt-1/">scraper</a>.</p> <p><strong>2)</strong> We take all these post titles and store them in a database for use later.</p> <p><strong>3)</strong> Next we&#8217;ll need to create our own custom XML feed. So we&#8217;ll take 100 or so random post topics from our database and use a script to generate a .xml RSS or ATOM file. Inside that RSS file we&#8217;ll include each individual Title as our Post Title. We&#8217;ll put in our own custom description (could be a selling point for our site). Then we&#8217;ll put our actual site&#8217;s address as the Source URL. So that the RSS Scraper sites will link to us instead of someone else.</p> <p><strong>4)</strong> After that we&#8217;ll need to let the three popular RSS Aggregators listed above (Google,Yahoo,Daypop) know that our xml file exists. So, using a third script, we&#8217;ll go to their submission forms and automatically fill and submit each form with the URL to our RSS feed file(www.mydomain.com/rss1.xml). Here are the forms:</p> <p><a target="_blank" href="http://blogsearch.google.com/ping">Google Blog Search</a><br /> <a target="_blank" href="http://search.yahoo.com/mrss/submit">Yahoo News Search</a><br /> <a target="_blank" href="http://www.daypop.com/info/submit.htm">Daypop RSS Search</a></p> <p>Once the form is submitted than you are done! Your fake posts will now be included in the RSS Aggregators search results. Then all future Splog updates that use the RSS Aggregators to find their content will automatically pickup your fake posts and publish them. They will give you a link and drive traffic to whatever URL you specify. Want it to go to direct affiliate offers? Sure! Want your money making site to get tens of thousands of inbound links? Sure! It&#8217;s all possible from there, its just how do you want to twist it to your advantage.</p> <p>I hope this cleared up the subject. Now that you know what you&#8217;re doing you are welcome to read the original post and figure out how to actually accomplish it from the technical view.</p> <p><a href="/100s-of-linkshour-automated-introduction-to-black-hole-seo/"><strong>100&#8217;s Of Automated Links/Hour </strong></a> </p>  	<p class="post-info"> 													 	</p> 	<!-- 		<rdf:RDF xmlns:rdf="/web/20130508093228/http://www.w3.org/1999/02/22-rdf-syntax-ns#" 	    xmlns:dc="/web/20130508093228/http://purl.org/dc/elements/1.1/" 	    xmlns:trackback="/web/20130508093228/http://madskills.com/public/xml/rss/module/trackback/"> 		<rdf:Description rdf:about="/web/20130508093228/http://www.bluehatseo.com/follow-up-to-100s-of-automated-linkshour-post/"     dc:identifier="/web/20130508093228/http://www.bluehatseo.com/follow-up-to-100s-of-automated-linkshour-post/"     dc:title="Follow Up To 100&#8217;s Of Automated Links/Hour Post"     trackback:ping="/web/20130508093228/http://www.bluehatseo.com/follow-up-to-100s-of-automated-linkshour-post/trackback/" /> </rdf:RDF>	--> </div> <div class="post-footer"><a href="/follow-up-to-100s-of-automated-linkshour-post/#comments" title="Comment on Follow Up To 100&#8217;s Of Automated Links/Hour Post">171 Comments &#187;</a></div>									</div> 							 				<div class="post"> 					<div class="post-title"><em><a href="/category/black-hole-seo/" title="View all posts in Black Hole SEO" rel="category tag">Black Hole SEO</a></em>05 May 2007 12:06 am</div> <p class="post-info"><a href="/100s-of-linkshour-automated-introduction-to-black-hole-seo/" rel="bookmark" title="Permanent Link: 100&#8217;s Of Links/Hour Automated - Introduction To Black Hole SEO"><b>100&#8217;s Of Links/Hour Automated - Introduction To Black Hole SEO</b></a></p> <div class="post-content" align="justified"> 	<p>I really am holding a glass of Guinness right now so in all the authority it holds&#8230;Cheers! I&#8217;m kind of excited about this post because frankly it&#8217;s been a long time coming. For the last 7-9 months or so I&#8217;ve been hinting and hinting that there is more to Black Hat than people are willing to talk about. As &#8220;swell&#8221; as IP delivery and blog spam are there&#8217;s an awesome subculture of Black Hats that takes the rabbit hole quite a bit deeper than you can probably imagine. This is called <strong>Black Hole SEO</strong>. By no means am I an expert on it, but over the last few years I&#8217;ve been getting in quite a bit of practice and starting to really kick some ass with it. In the gist, Black Hole SEO is the deeper darker version of black hat. It&#8217;s the kind of stuff that makes those pioneering Black Hat Bloggers who dispel secrets like parasite hosting and link injection techniques look like pussies. Without getting into straight up hacking its the stuff black hatters dream about pulling off, and I am strangely comfortable with kicking in some doors on the subject. However lets start small and simple for now. Than if it takes well we&#8217;ll work our way up to some shit that&#8217;ll just make you laugh its so off the wall. Admit it, at one point you didn&#8217;t even think Advanced SEO existed. <img src='/wp-includes/images/smilies/icon_smile.gif' alt=':)' class='wp-smiley' /> </p> <p>In my <a href="/parabole-whitehat-vs-blackhat/">White &#038; Black Hat Parable</a> post I subtly introduced this technique as well as the whole Black Hole SEO concept. It doesn&#8217;t really have a name but basically it follows all the rules of Black Hole SEO. It targets sites on a mass scale, particularly scraper sites. It tricks them into giving you legitimate and targeted links and it grabs its content on an authoritative scale (will be explained in a later related post). So lets begin our Black Hole SEO lesson by learning how to grab hundreds of links an hour in a completely automated and consenting method.</p> <p><strong>Objective</strong><br /> We will attempt to get black hat or scraper sites to mass grab our generated content and link to us. It&#8217;ll target just about every RSS scraper site out there, including Blog Solution and RSSGM installs including many private scrapers and Splogs.</p> <p><strong>Methodology</strong><br /> <strong>1)</strong>  First we&#8217;ll look at niche and target sources. Everyone knows the top technique for an RSS scraper is the classic Blog N&#8217; Ping method. It&#8217;s basically where you create a scraped blog post from a search made on a popular Blog Aggregator like Google Blog Search or Yahoo Blog Search. Then they ping popular blog update services to get the post indexed by the engines. For a solid list of these checkout <a target="_blank" href="http://www.pingomatic.com">PingOMatic.com</a>. Something to chew on, how many of you actually go to Weblogs.com to look for new interesting blog posts? Haha yeah thats what I thought. 90% of the posts there are pinged from spam RSS scraper blogs. On top of that there&#8217;s hundreds going in an hour. Kinda funny, but a great place to find targets for our link injections none the less.</p> <p><strong>2)</strong> We&#8217;ll take Weblogs.com as an example. We know that at least 90% of those updates will be from RSS scrapers that will eventually update and grab more RSS content based upon their specified keywords. We know that the posts they make already contain the keywords they are looking for, otherwise they wouldn&#8217;t of scraped them in the first place. We also have a good idea of where they are getting their RSS content. So all we got to do is find what they want, where they are getting it from, change it up to benefit us, and give it back. <img src='/wp-includes/images/smilies/icon_smile.gif' alt=':)' class='wp-smiley' /> </p> <p><strong>3)</strong>  Write a simple script to to scrape all the post titles within the td class=&#8221;blogname&#8221; located between the !&#8211; START - WEBLOGS PING ROLLER &#8212;     comments within the html. Once you got a list of all the titles store it in a database and keep doing it infinitely. Check for duplicates and continuously remove them.</p> <p><strong>4)</strong> Once you got all the titles steadily coming in write a small script on your site that outputs the titles into a rolling XML feed. I know I&#8217;m going to get questions about what a &#8220;rolling XML feed&#8221; is so I&#8217;ll just go ahead and answer them. It&#8217;s nothing more than an xml feed that basically updates in real time. You just keep adding posts to it as they come in and removing the previous ones. If the delay is too heavy you can always either make the feed larger (up to about 100 posts is usually fine) or you can create multiple XML feeds to accommodate the inevitably tremendous volume. I personally like the multiple feed idea.</p> <p><strong>5)</strong> Give each post within the feed the same title as you scraped from Weblogs. Then change the URL output field to your website address. Not the original! Haha that would do no good obviously. Then create a nice little sales post for your site. Don&#8217;t forget to include some html links inside your post content just in case their software forgets to remove it.</p> <p><strong>6)</strong> Ping a bunch of popular RSS blog search sites. The top 3 you should go for are:<br /> <a target="_blank" href="http://blogsearch.google.com/ping">Google Blog Search</a><br /> <a target="_blank" href="http://search.yahoo.com/mrss/submit">Yahoo News Search</a><br /> <a target="_blank" href="http://www.daypop.com/info/submit.htm">Daypop RSS Search</a></p> <p>This will republish your changed up content so the RSS scrapers and all the sites you scraped the titles from will grab and republish your content once again. However, this time with your link.  This won&#8217;t have any affect on legitimate sites or services so there really are no worries.  Fair warning: be sure to make the link you want to inject into all these Splogs and scraped sites as a quickly changed and updated variable because this will gain you links VERY quickly. Lets just say I wasn&#8217;t exaggerating in the title <img src='/wp-includes/images/smilies/icon_smile.gif' alt=':)' class='wp-smiley' />  A good idea would be to put the link in the database, and every time the XML publishing script loops through have it query it from the database. That way you can change it on the fly as it continuously runs.</p> <p>As you&#8217;ve probably started to realize this technique doesn&#8217;t just stop at gaining links quickly, it&#8217;s also a VERY powerful affiliate marketing tool. I started playing around with this technique before <a href="/affiliate-marketing-through-rss-feeds/">last June</a> and it still works amazingly. The switch to direct affiliate marketing is easy. Instead of putting in your URL, grab related affiliate offers and once you got a big enough list start matching for related keywords before you republish the XML feed. If a match is made, put in the affiliate link instead of your link and instead of the bullshit post content put in a quick prewritten sales post for that particular offer. The Black Hat sites will work hard to drive the traffic to the post and rank for the terms and you&#8217;ll be the one to benefit. <img src='/wp-includes/images/smilies/icon_smile.gif' alt=':)' class='wp-smiley' /> </p> <p>Each individual site may not give you much but when you scale it to several thousands of sites a day it starts really adding up quickly. By quickly I mean watch out. By no means is that a joke. It is quick. There are more RSS scraped pages and sites that go up everyday than any of us could possibly monetize no matter how fast you think your servers are. </p>  	<p class="post-info"> 													 	</p> 	<!-- 		<rdf:RDF xmlns:rdf="/web/20130508093228/http://www.w3.org/1999/02/22-rdf-syntax-ns#" 	    xmlns:dc="/web/20130508093228/http://purl.org/dc/elements/1.1/" 	    xmlns:trackback="/web/20130508093228/http://madskills.com/public/xml/rss/module/trackback/"> 		<rdf:Description rdf:about="/web/20130508093228/http://www.bluehatseo.com/100s-of-linkshour-automated-introduction-to-black-hole-seo/"     dc:identifier="/web/20130508093228/http://www.bluehatseo.com/100s-of-linkshour-automated-introduction-to-black-hole-seo/"     dc:title="100&#8217;s Of Links/Hour Automated - Introduction To Black Hole SEO"     trackback:ping="/web/20130508093228/http://www.bluehatseo.com/100s-of-linkshour-automated-introduction-to-black-hole-seo/trackback/" /> </rdf:RDF>	--> </div> <div class="post-footer"><a href="/100s-of-linkshour-automated-introduction-to-black-hole-seo/#comments" title="Comment on 100&#8217;s Of Links/Hour Automated - Introduction To Black Hole SEO">364 Comments &#187;</a></div>									</div> 						<p align="center"></p>		 					 	</div> 	<div id="sidebar">		 		<li class="pagenav"><h2>Pages</h2><ul><li class="page_item"><a href="/contribute/" title="Contribute">Contribute</a></li> <li class="page_item"><a href="/have-a-question/" title="Have A Question?">Have A Question?</a></li> <li class="page_item"><a href="/what-is-blue-hat-seo/" title="What Is Blue Hat SEO?">What Is Blue Hat SEO?</a></li> </ul></li> <h2>Categories:</h2> 	<ul>	<li><a href="/category/general-articles/" title="View all posts filed under General Articles">General Articles</a> (55) </li> 	<li><a href="/category/blue-hat-techniques/" title="View all posts filed under Blue Hat Techniques">Blue Hat Techniques</a> (21) </li> 	<li><a href="/category/random-thoughts/" title="View all posts filed under Random Thoughts">Random Thoughts</a> (42) </li> 	<li><a href="/category/site-reviews-commentary/" title="View all posts filed under Site Reviews &#038; Commentary">Site Reviews &#038; Commentary</a> (8) </li> 	<li><a href="/category/seo-tools/" title="View all posts filed under SEO Tools">SEO Tools</a> (9) </li> 	<li><a href="/category/announcements/" title="View all posts filed under Announcements">Announcements</a> (17) </li> 	<li><a href="/category/update-reports/" title="View all posts filed under Update Reports">Update Reports</a> (2) </li> 	<li><a href="/category/neat-tricks-and-hacks/" title="View all posts filed under Neat Tricks and Hacks">Neat Tricks and Hacks</a> (19) </li> 	<li><a href="/category/guides/" title="View all posts filed under Guides">Guides</a> (5) </li> 	<li><a href="/category/user-contributed/" title="View all posts filed under User Contributed">User Contributed</a> (9) </li> 	<li><a href="/category/check-mates/" title="View all posts filed under Check Mates">Check Mates</a> (4) </li> 	<li class="current-cat"><a href="/category/black-hole-seo/" title="View all posts filed under Black Hole SEO">Black Hole SEO</a> (4) </li> </ul>  <h2><label for="s">Search:</label></h2> 	<ul> 		<li> 			<form id="searchform" method="get" action="/web/20130508093228/http://www.bluehatseo.com/index.php"> 				<div> 					<p><input type="text" name="s" id="s" size="15" /></p> 					<p><input type="submit" name="submit" value="Search" /></p> 				</div> 			</form> 		</li> 	</ul> <h2>Monthly:</h2> 	<ul>	<li><a href='/2011/06/' title='June 2011'>June 2011</a>&nbsp;(1)</li> 	<li><a href='/2010/07/' title='July 2010'>July 2010</a>&nbsp;(2)</li> 	<li><a href='/2010/06/' title='June 2010'>June 2010</a>&nbsp;(1)</li> 	<li><a href='/2009/11/' title='November 2009'>November 2009</a>&nbsp;(2)</li> 	<li><a href='/2009/09/' title='September 2009'>September 2009</a>&nbsp;(1)</li> 	<li><a href='/2009/06/' title='June 2009'>June 2009</a>&nbsp;(2)</li> 	<li><a href='/2009/04/' title='April 2009'>April 2009</a>&nbsp;(1)</li> 	<li><a href='/2009/02/' title='February 2009'>February 2009</a>&nbsp;(1)</li> 	<li><a href='/2008/11/' title='November 2008'>November 2008</a>&nbsp;(1)</li> 	<li><a href='/2008/09/' title='September 2008'>September 2008</a>&nbsp;(1)</li> 	<li><a href='/2008/08/' title='August 2008'>August 2008</a>&nbsp;(1)</li> 	<li><a href='/2008/07/' title='July 2008'>July 2008</a>&nbsp;(2)</li> 	<li><a href='/2008/05/' title='May 2008'>May 2008</a>&nbsp;(2)</li> 	<li><a href='/2008/03/' title='March 2008'>March 2008</a>&nbsp;(3)</li> 	<li><a href='/2007/12/' title='December 2007'>December 2007</a>&nbsp;(5)</li> 	<li><a href='/2007/10/' title='October 2007'>October 2007</a>&nbsp;(2)</li> 	<li><a href='/2007/09/' title='September 2007'>September 2007</a>&nbsp;(1)</li> 	<li><a href='/2007/08/' title='August 2007'>August 2007</a>&nbsp;(1)</li> 	<li><a href='/2007/07/' title='July 2007'>July 2007</a>&nbsp;(3)</li> 	<li><a href='/2007/06/' title='June 2007'>June 2007</a>&nbsp;(8)</li> 	<li><a href='/2007/05/' title='May 2007'>May 2007</a>&nbsp;(4)</li> 	<li><a href='/2007/04/' title='April 2007'>April 2007</a>&nbsp;(8)</li> 	<li><a href='/2007/03/' title='March 2007'>March 2007</a>&nbsp;(4)</li> 	<li><a href='/2007/02/' title='February 2007'>February 2007</a>&nbsp;(3)</li> 	<li><a href='/2007/01/' title='January 2007'>January 2007</a>&nbsp;(6)</li> 	<li><a href='/2006/12/' title='December 2006'>December 2006</a>&nbsp;(8)</li> 	<li><a href='/2006/11/' title='November 2006'>November 2006</a>&nbsp;(12)</li> 	<li><a href='/2006/10/' title='October 2006'>October 2006</a>&nbsp;(13)</li> 	<li><a href='/2006/09/' title='September 2006'>September 2006</a>&nbsp;(5)</li> 	<li><a href='/2006/08/' title='August 2006'>August 2006</a>&nbsp;(10)</li> 	<li><a href='/2006/07/' title='July 2006'>July 2006</a>&nbsp;(12)</li> 	<li><a href='/2006/06/' title='June 2006'>June 2006</a>&nbsp;(4)</li> 	<li><a href='/2006/05/' title='May 2006'>May 2006</a>&nbsp;(4)</li> 	<li><a href='/2006/04/' title='April 2006'>April 2006</a>&nbsp;(15)</li> 	<li><a href='/2006/03/' title='March 2006'>March 2006</a>&nbsp;(14)</li> 	<li><a href='/2006/02/' title='February 2006'>February 2006</a>&nbsp;(15)</li> 	<li><a href='/2006/01/' title='January 2006'>January 2006</a>&nbsp;(15)</li> </ul>  <h2>RSS Feeds:</h2> 	<ul> 		<li><a href="http://feeds.feedburner.com/BlueHatSEO/HXKR" title="Subscribe to my feed" rel="alternate" type="application/rss+xml"></a><a href="http://feeds.feedburner.com/BlueHatSEO/HXKR" title="Subscribe to my feed" rel="alternate" type="application/rss+xml">Subscribe in a reader</a> 			<a title="RSS2 Feed for Posts" href="/feed/">Posts</a> | <a title="RSS2 Feed for Comments" href="/comments/feed/">Comments</a></li>	 	</ul>	 <li> <h2>Recent Comments</h2> <ul><li><strong>AC Repairing Service:</strong> <a href="/seo-checklist-for-e-commerce-sites/#comment-622623" title="View the entire comment by AC Repairing Service">This is a really good site post, im delighted I...</a></li><li><strong>jyotistilbon:</strong> <a href="/open-questions-when-to-never-do-article-submissions/#comment-622620" title="View the entire comment by jyotistilbon">Belastingadvies Breda    Wij van AQM Advies verzorgen niet alleen de jaarlijkse...</a></li><li><strong>game bigone:</strong> <a href="/guest-post-how-to-start-your-first-media-buy/#comment-622611" title="View the entire comment by game bigone">Good work. Thanks for the info. very useful tips indeed.  ...</a></li><li><strong>Vacuum Cleaners Auckland:</strong> <a href="/open-questions-when-to-never-do-article-submissions/#comment-622606" title="View the entire comment by Vacuum Cleaners Auckland">Thanks to share this news... it's really helpful to me....</a></li><li><strong>Michael:</strong> <a href="/guest-post-how-to-start-your-first-media-buy/#comment-622588" title="View the entire comment by Michael">Thats a very well written article. Very interesting, you are...</a></li><li><strong>Jasa SEO:</strong> <a href="/proper-use-of-rssgm/#comment-622584" title="View the entire comment by Jasa SEO">It still working?...</a></li><li><strong>Event Staffing Agency:</strong> <a href="/conspiracy-theories-please/#comment-622582" title="View the entire comment by Event Staffing Agency">That's a good article and i want to refer this...</a></li><li><strong>Oficinas Amobladas:</strong> <a href="/how-to-take-down-a-competitors-website-legally/#comment-622579" title="View the entire comment by Oficinas Amobladas">Your articles are always so complete... Love your blog...</a></li><li><strong>Oficina Virtual:</strong> <a href="/product-review-auto-stumble/#comment-622578" title="View the entire comment by Oficina Virtual">it's a great product...</a></li><li><strong>Oficinas en Arriendo:</strong> <a href="/open-questions-4-deminishing-values-on-outbound-links/#comment-622577" title="View the entire comment by Oficinas en Arriendo">Thank you for the information, it's too complete.....</a></li></ul> </li> <li> <h2>Top Commentators</h2> <ul><li><a href='http://www.discussweightloss.com'>Weight Loss</a> (131) </li> <li><a href='http://sayyesyoga.com'>Yoga</a> (121) </li> <li><a href='http://www.visiblexposure.com'>visiblexposure.com</a> (118) </li> <li><a href='http://www.celebritiesjewellery.com'>Jewellery</a> (113) </li> <li><a href='http://www.goanxietyfree.com'>Aniexty</a> (100) </li> <li><a href='http://www.planetofphotography.com'>Planet of Photography</a> (97) </li> <li><a href='http://vindicatemj.wordpress.com'>Vindicatemj</a> (94) </li> <li><a href='http://technocrathub.com'>Technocrathub</a> (91) </li> <li><a href='http://propertymarbellaapartments.com'>Property Marbella</a> (87) </li> <li><a href='http://flavaflav.atspace.co.uk'>Lee</a> (82) </li> </ul> </li> 	</div> <p id="footer">  <small>Template by <a href="http://www.myspaceimagecodes.net">Myspace Image Codes</a> available at <a href="http://www.moshable.com">Free Music</a>. Check Out My Other Site <a href="http://www.mp3search.fm">MP3 Search</a>  Credit to </a>.</small>  </div>  </body> </html>     <!--       9:32:28 May 8, 2013        21:32:21 Jan 26, 2017.                    --> 