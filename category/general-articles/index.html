<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"> <html xmlns="http://www.w3.org/1999/xhtml"> <head profile="http://gmpg.org/xfn/1">   <script type="text/javascript" src="/static/js/analytics.js"></script> <script type="text/javascript">archive_analytics.values.server_name="wwwb-app10.us.archive.org";archive_analytics.values.server_ms=1460;</script> <link type="text/css" rel="stylesheet" href="/static/css/banner-styles.css"/>   <link rel="icon" href="/favicon.ico" type="image/x-icon">  	<title>Blue Hat SEO-Advanced SEO Tactics &raquo; General Articles</title> 	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /> 	<meta name="generator" content="WordPress 2.0.7" /> <!-- leave this for stats please --> 	<style type="text/css" media="screen"> 		@import url(../../wp-content/themes/fasttrack/style.css); 	</style> 	<link rel="alternate" type="application/rss+xml" title="RSS 2.0" /> 	<link rel="alternate" type="text/xml" title="RSS .92" /> 	<link rel="alternate" type="application/atom+xml" title="Atom 0.3" /> 	<link rel="pingback" />     	<link rel='archives' title='June 2011' /> 	<link rel='archives' title='July 2010' /> 	<link rel='archives' title='June 2010' /> 	<link rel='archives' title='November 2009' /> 	<link rel='archives' title='September 2009' /> 	<link rel='archives' title='June 2009' /> 	<link rel='archives' title='April 2009' /> 	<link rel='archives' title='February 2009' /> 	<link rel='archives' title='November 2008' /> 	<link rel='archives' title='September 2008' /> 	<link rel='archives' title='August 2008' /> 	<link rel='archives' title='July 2008' /> 	<link rel='archives' title='May 2008' /> 	<link rel='archives' title='March 2008' /> 	<link rel='archives' title='December 2007' /> 	<link rel='archives' title='October 2007' /> 	<link rel='archives' title='September 2007' /> 	<link rel='archives' title='August 2007' /> 	<link rel='archives' title='July 2007' /> 	<link rel='archives' title='June 2007' /> 	<link rel='archives' title='May 2007' /> 	<link rel='archives' title='April 2007' /> 	<link rel='archives' title='March 2007' /> 	<link rel='archives' title='February 2007' /> 	<link rel='archives' title='January 2007' /> 	<link rel='archives' title='December 2006' /> 	<link rel='archives' title='November 2006' /> 	<link rel='archives' title='October 2006' /> 	<link rel='archives' title='September 2006' /> 	<link rel='archives' title='August 2006' /> 	<link rel='archives' title='July 2006' /> 	<link rel='archives' title='June 2006' /> 	<link rel='archives' title='May 2006' /> 	<link rel='archives' title='April 2006' /> 	<link rel='archives' title='March 2006' /> 	<link rel='archives' title='February 2006' /> 	<link rel='archives' title='January 2006' /> 	 <!-- tdomf: no posts to fix! -->  <script>   <!--    		// remote scripting library 		// (c) copyright 2005 modernmethod, inc 		var sajax_debug_mode = false; 		var sajax_request_type = "GET"; 		var sajax_target_id = ""; 		var sajax_failure_redirect = "";  		function sajax_debug(text) { 			if (sajax_debug_mode) 				alert(text); 		}   		function sajax_init_object() {  			sajax_debug("sajax_init_object() called..")   			var A;   			var msxmlhttp = new Array( 				'Msxml2.XMLHTTP.5.0', 				'Msxml2.XMLHTTP.4.0', 				'Msxml2.XMLHTTP.3.0', 				'Msxml2.XMLHTTP', 				'Microsoft.XMLHTTP'); 			for (var i = 0; i < msxmlhttp.length; i++) { 				try { 					A = new ActiveXObject(msxmlhttp[i]); 				} catch (e) { 					A = null; 				} 			}  			if(!A && typeof XMLHttpRequest != "undefined") 				A = new XMLHttpRequest(); 			if (!A) 				sajax_debug("Could not create connection object."); 			return A; 		}  		var sajax_requests = new Array();  		function sajax_cancel() { 			for (var i = 0; i < sajax_requests.length; i++) 				sajax_requests[i].abort(); 		}  		function sajax_do_call(func_name, args) { 			var i, x, n; 			var uri; 			var post_data; 			var target_id;  			sajax_debug("in sajax_do_call().." + sajax_request_type + "/" + sajax_target_id); 			target_id = sajax_target_id; 			if (typeof(sajax_request_type) == "undefined" || sajax_request_type == "") 				sajax_request_type = "GET";  			uri = "/category/general-articles/"; 			if (sajax_request_type == "GET") {  				if (uri.indexOf("?") == -1) 					uri += "?rs=" + escape(func_name); 				else 					uri += "&rs=" + escape(func_name); 				uri += "&rst=" + escape(sajax_target_id); 				uri += "&rsrnd=" + new Date().getTime();  				for (i = 0; i < args.length-1; i++) 					uri += "&rsargs[]=" + escape(args[i]);  				post_data = null; 			} 			else if (sajax_request_type == "POST") { 				post_data = "rs=" + escape(func_name); 				post_data += "&rst=" + escape(sajax_target_id); 				post_data += "&rsrnd=" + new Date().getTime();  				for (i = 0; i < args.length-1; i++) 					post_data = post_data + "&rsargs[]=" + escape(args[i]); 			} 			else { 				alert("Illegal request type: " + sajax_request_type); 			}  			x = sajax_init_object(); 			if (x == null) { 				if (sajax_failure_redirect != "") { 					location.href = sajax_failure_redirect; 					return false; 				} else { 					sajax_debug("NULL sajax object for user agent:\n" + navigator.userAgent); 					return false; 				} 			} else { 				x.open(sajax_request_type, uri, true); 				// window.open(uri);  				sajax_requests[sajax_requests.length] = x;  				if (sajax_request_type == "POST") { 					x.setRequestHeader("Method", "POST " + uri + " HTTP/1.1"); 					x.setRequestHeader("Content-Type", "application/x-www-form-urlencoded"); 				}  				x.onreadystatechange = function() { 					if (x.readyState != 4) 						return;  					sajax_debug("received " + x.responseText);  					var status; 					var data; 					var txt = x.responseText.replace(/^\s*|\s*$/g,""); 					status = txt.charAt(0); 					data = txt.substring(2);  					if (status == "") { 						// let's just assume this is a pre-response bailout and let it slide for now 					} else if (status == "-") 						alert("Error: " + data); 					else { 						if (target_id != "") 							document.getElementById(target_id).innerHTML = eval(data); 						else { 							try { 								var callback; 								var extra_data = false; 								if (typeof args[args.length-1] == "object") { 									callback = args[args.length-1].callback; 									extra_data = args[args.length-1].extra_data; 								} else { 									callback = args[args.length-1]; 								} 								callback(eval(data), extra_data); 							} catch (e) { 								sajax_debug("Caught error " + e + ": Could not eval " + data ); 							} 						} 					} 				} 			}  			sajax_debug(func_name + " uri = " + uri + "/post = " + post_data); 			x.send(post_data); 			sajax_debug(func_name + " waiting.."); 			delete x; 			return true; 		}  		 		// wrapper for tdomf_ajax_send_post 		function x_tdomf_ajax_send_post() { 			sajax_do_call("tdomf_ajax_send_post", 				x_tdomf_ajax_send_post.arguments); 		}  		  // DHTML email validation script. Courtesy of SmartWebby.com (/web/20130510105514/http://www.smartwebby.com/dhtml/)   function echeck(str) {     var at="@"     var dot="."     var lat=str.indexOf(at)     var lstr=str.length 		var ldot=str.indexOf(dot) 		if (str.indexOf(at)==-1){ 		   //alert("Invalid E-mail ID") 		   return false 		} 		if (str.indexOf(at)==-1 || str.indexOf(at)==0 || str.indexOf(at)==lstr){ 		   //alert("Invalid E-mail ID") 		   return false 		} 		if (str.indexOf(dot)==-1 || str.indexOf(dot)==0 || str.indexOf(dot)==lstr){ 		    //alert("Invalid E-mail ID") 		    return false 		} 		 if (str.indexOf(at,(lat+1))!=-1){ 		    //alert("Invalid E-mail ID") 		    return false 		 } 		 if (str.substring(lat-1,lat)==dot || str.substring(lat+1,lat+2)==dot){ 		    //alert("Invalid E-mail ID") 		    return false 		 } 		 if (str.indexOf(dot,(lat+2))==-1){ 		    //alert("Invalid E-mail ID") 		    return false 		 } 		 if (str.indexOf(" ")!=-1){ 		    //alert("Invalid E-mail ID") 		    return false 		 }      return true					   }    -->   </script>   <script>   <!--   function tdomf_clear_form() {     document.getElementById("tdomf_form1_title").value = "";     document.getElementById("tdomf_form1_content").value = "";     var e1 = document.getElementById("tdomf_form1_notify");     if(e1 != null) { e1.checked = true; }     var e2 = document.getElementById("tdomf_form1_email");     if(e2 != null) { e2.value = ""; }     var e3 = document.getElementById("tdomf_form1_name");     if(e3 != null) { e3.value = ""; }     document.getElementById("tdomf_form1_msg_div").innerHTML = "";     document.getElementById("tdomf_form1_div").style.display = 'block';   }   function tdomf_send_form_cb(message) {     document.getElementById("tdomf_form1_msg_div").innerHTML = message;   }   function tdomf_send_form() {     var message = document.getElementById("tdomf_form1_msg_div");          var title = document.getElementById("tdomf_form1_title").value;     var content = document.getElementById("tdomf_form1_content").value;      var error = "";     if(title.length == 0){ error += "You must specify a title.<br/>"; }     if(content.length == 0){ error += "You must add some text.<br/>"; }          var name = "";     var e1 = document.getElementById("tdomf_form1_name");     if(e1 != null){        name = e1.value;        if(name.length == 0){          error += "You must specify a name so we know who it comes from.<br/>";        }     }     var email = "";     var e2 = document.getElementById("tdomf_form1_email");     if(e2 != null){        email = e2.value;        if(echeck(email) == false){          error += "The email you specified is invalid.<br/>";        }     }          var web = "";     var e3 = document.getElementById("tdomf_form1_web");     if(e3 != null){       web = e3.value;     }          var notify = false;     var e3 = document.getElementById("tdomf_form1_notify");     if(e3 != null){ notify = e3.checked; }          if(error.length > 0) {       message.innerHTML = '<font color="red">' + error + '</font>';     } else {       var theform = document.getElementById("tdomf_form1_div");       theform.style.display = 'none';       message.innerHTML = '<center><img src="/web/20130510105514/http://www.bluehatseo.com/wp-content/plugins/TDOMiniForms/ajax-loader.gif" /></center>';       x_tdomf_ajax_send_post(title, content, notify, email, name, web, tdomf_send_form_cb);     }   }   -->   </script> <script language="javascript" type="text/javascript"> <!-- 		function collapseThread( theId ) { 			var comment = document.getElementById(theId); 			if(!comment) 			{ 				alert("ERROR:\nThe document structure is different\nfrom what Threaded Comments expects.\nYou are missing the element '"+theId+"'"); 				return; 			} 			var theBody = findBody(comment); 			if(comment.className.indexOf("collapsed") > -1) { 				comment.className = comment.className.replace(" collapsed", "");; 			} else { 				comment.className += " collapsed"; 			} 		}  		function expandThread( theId ) { 			var comment = document.getElementById(theId); 			if(!comment) 			{ 				alert("ERROR:\nThe document structure is different\nfrom what Threaded Comments expects.\nYou are missing the element '"+theId+"'"); 				return; 			} 			var theBody = findBody(comment); 			if(comment.className.indexOf("collapsed") > -1) { 				comment.className = comment.className.replace(" collapsed", "");; 			}  		} 		 		function findBody(el) 		{ 			var divs = el.getElementsByTagName("div"); 			var ret; 			for(var i = 0; i < divs.length; ++i) { 				if(divs.item(i).className.indexOf("body") > -1) 					return divs.item(i); 			} 			return false; 		} 	 		function onAddComment() { 			//checkDocumentIntegrity(); 			var el = document.getElementById("commentform"); 			// Future release: Check if form is filled correctly and mark the form fields. 			el.submit(); 		} 		 		function moveAddCommentBelow(theId, threadId, collapse) 		{ 			expandThread( theId ); 			var addComment = document.getElementById("addcomment"); 			if(!addComment) 			{ 			  	alert("ERROR:\nThreaded Comments can't find the 'addcomment' div.\nThis is probably because you have changed\nthe comments.php file.\nMake sure there is a tag around the form\nthat has the id 'addcomment'");  				return 			} 			var comment = document.getElementById(theId); 			if(collapse) 			{ 				for(var i = 0; i < comment.childNodes.length; ++i) { 					var c = comment.childNodes.item(i); 					if(typeof(c.className) == "string" && c.className.indexOf("collapsed")<0) { 						c.className += " collapsed"; 					} 				} 			} 			addComment.parentNode.removeChild(addComment);  			comment.appendChild(addComment); 			if(comment.className.indexOf("alt")>-1) { 				addComment.className = addComment.className.replace(" alt", "");					 			} else { 				addComment.className += " alt"; 			} 		        var replyId = document.getElementById("comment_reply_ID"); 			if(replyId == null) 			{ 				alert("Brians Threaded Comments Error:\nThere is no hidden form field called\n'comment_reply_ID'. This is probably because you\nchanged the comments.php file and forgot\nto include the field. Please take a look\nat the original comments.php and copy the\nform field over."); 			} 			replyId.value = threadId; 			var reRootElement = document.getElementById("reroot"); 			if(reRootElement == null) 			{ 				alert("Brians Threaded Comments Error:\nThere is no anchor tag called 'reroot' where\nthe comment form starts.\nPlease compare your comments.php to the original\ncomments.php and copy the reroot anchor tag over."); 			} 			reRootElement.style.display = "block"; 			var aTags = comment.getElementsByTagName("A"); 			var anc = aTags.item(0).id; 			//document.location.href = "#"+anc; 			document.getElementById("comment").focus(); 		}  		function checkDocumentIntegrity() 		{ 			str = ""; 			 			str += checkElement("reroot","div tag"); 			str += checkElement("addcomment", "div tag"); 			str += checkElement("comment_reply_ID", "hidden form field"); 			str += checkElement("content", "div tag"); 			str += checkElement("comment", "textfield"); 			str += checkElement("addcommentanchor", "anchor tag"); 			 			if(str != "") 			{ 				str = "Brian's Threaded Comments are missing some of the elements that are required for it to function correctly.\nThis is probably the because you have changed the original comments.php that was included with the plugin.\n\nThese are the errors:\n" + str; 				str += "\nYou should compare your comments.php with the original comments.php and make sure the required elements have not been removed.";  				alert(str); 			} 		}                 		function checkElement(theId, elDesc) 		{ 			var el = document.getElementById(theId); 			if(!el) 			{ 				if(elDesc == null) 					elDesc = "element"; 				return "- The "+elDesc+" with the ID '" +theId + "' is missing\n";  			} 			else  				return ""; 		} 		 		function reRoot() 		{ 			var addComment = document.getElementById("addcomment");			 			var reRootElement = document.getElementById("reroot"); 			reRootElement.style.display = "none"; 			var content = document.getElementById("content"); 			addComment.parentNode.removeChild(addComment); 			content.appendChild(addComment); 			addComment.className = addComment.className.replace(" alt", ""); 			document.location.href = "#addcommentanchor"; 			document.getElementById("comment").focus();				 			document.getElementById("comment_reply_ID").value = "0"; 		}			 		 		function changeCommentSize(d) 		{ 			var el = document.getElementById("comment"); 			var height = parseInt(el.style.height); 			if(!height && el.offsetHeight) 				height = el.offsetHeight; 			height += d; 			if(height < 20)  				height = 20; 			el.style.height = height+"px"; 		}		 --> </script> <style type="text/css"> .comment  { 	position: 				relative; 	margin:					3px; 	margin-top:				6px; /*	border: 				1px solid #666; */ 	padding:				4px 4px 4px 8px; 	font-size:				98%; 	background-color:		#fff; }  .odd { 	background-color: #f8f8f8; }  .comment div { 	position: 				relative; }  .comment .comment img { 	margin: 				0px; }  .comment .collapseicon  { 	width: 					13px; 	height: 				13px; 	overflow:				hidden; 	background-image: 		url(../../wp-content/plugins/briansthreadedcomments.php?image=subthread-open.png); }  .collapsed .collapseicon  { 	background-image: 		url(../../wp-content/plugins/briansthreadedcomments.php?image=subthread.png); }   .comment .reply { 	text-align: 			right; 	font-size: 				80%; 	padding: 				0px 6px 6px 0px; }  .comment { 	border: 	1px solid #ddd; 	margin-top: 			10px; }  input#subscribe { 	width: auto; }  .comment .body .content { 	padding:				0px 3px 0px 3px; 	width: 					100%;	 	overflow: 				auto;  }  .comment .title abbr { 	border: none; }  .collapsed .body, .collapsed .comment { 	display:				none; } /* #addcomment small, #addcomment div { 	padding:				3px; } */ #commentform textarea { 	width: 97%; } </style> </head>  <body id="archives">    <script type="text/javascript" src="/static/js/disclaim-element.js" ></script> <script type="text/javascript" src="/static/js/graph-calc.js" ></script> <script type="text/javascript">//<![CDATA[ var __wm = (function(imgWidth,imgHeight,yearImgWidth,monthImgWidth){ var wbPrefix = "/web/"; var wbCurrentUrl = "http://www.bluehatseo.com/category/general-articles/";  var firstYear = 1996; var displayDay = "10"; var displayMonth = "May"; var displayYear = "2013"; var prettyMonths = ["Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec"]; var $D=document,$=function(n){return document.getElementById(n)}; var trackerVal,curYear = -1,curMonth = -1; var yearTracker,monthTracker; function showTrackers(val) {   if (val===trackerVal) return;   var $ipp=$("wm-ipp");   var $y=$("displayYearEl"),$m=$("displayMonthEl"),$d=$("displayDayEl");   if (val) {     $ipp.className="hi";   } else {     $ipp.className="";     $y.innerHTML=displayYear;$m.innerHTML=displayMonth;$d.innerHTML=displayDay;   }   yearTracker.style.display=val?"inline":"none";   monthTracker.style.display=val?"inline":"none";   trackerVal = val; } function trackMouseMove(event,element) {   var eventX = getEventX(event);   var elementX = getElementX(element);   var xOff = Math.min(Math.max(0, eventX - elementX),imgWidth);   var monthOff = xOff % yearImgWidth;    var year = Math.floor(xOff / yearImgWidth);   var monthOfYear = Math.min(11,Math.floor(monthOff / monthImgWidth));   // 1 extra border pixel at the left edge of the year:   var month = (year * 12) + monthOfYear;   var day = monthOff % 2==1?15:1;   var dateString = zeroPad(year + firstYear) + zeroPad(monthOfYear+1,2) +     zeroPad(day,2) + "000000";    $("displayYearEl").innerHTML=year+firstYear;   $("displayMonthEl").innerHTML=prettyMonths[monthOfYear];   // looks too jarring when it changes..   //$("displayDayEl").innerHTML=zeroPad(day,2);   var url = wbPrefix + dateString + '/' +  wbCurrentUrl;   $("wm-graph-anchor").href=url;    if(curYear != year) {     var yrOff = year * yearImgWidth;     yearTracker.style.left = yrOff + "px";     curYear = year;   }   if(curMonth != month) {     var mtOff = year + (month * monthImgWidth) + 1;     monthTracker.style.left = mtOff + "px";     curMonth = month;   } } function hideToolbar() {   $("wm-ipp").style.display="none"; } function bootstrap() {   var $spk=$("wm-ipp-sparkline");   yearTracker=$D.createElement('div');   yearTracker.className='yt';   with(yearTracker.style){     display='none';width=yearImgWidth+"px";height=imgHeight+"px";   }   monthTracker=$D.createElement('div');   monthTracker.className='mt';   with(monthTracker.style){     display='none';width=monthImgWidth+"px";height=imgHeight+"px";   }   $spk.appendChild(yearTracker);   $spk.appendChild(monthTracker);    var $ipp=$("wm-ipp");   $ipp&&disclaimElement($ipp); } return{st:showTrackers,mv:trackMouseMove,h:hideToolbar,bt:bootstrap}; })(550, 27, 25, 2);//]]> </script> </style> <div id="wm-ipp" lang="en" style="display:none;"></div> </script>   <div id="rap"> 	<div id="header"> 	<h1><a href="/" title="Blue Hat SEO-Advanced SEO Tactics" style="color:#177efd;">Blue Hat SEO-Advanced SEO Tactics</a></h1> </div> 	 	<div id="content"> 					<h3>General Articles</h3> 			<div class="post-info">Archived Posts from this Category</div>		 			<br/>				 							 				<div class="post"> 					<div class="post-title"><em><a href="/category/general-articles/" title="View all posts in General Articles" rel="category tag">General Articles</a></em>09 Jul 2010 01:12 am</div> <p class="post-info"><a href="/seo-checklist-for-e-commerce-sites/" rel="bookmark" title="Permanent Link: SEO Checklist for E-Commerce Sites"><b>SEO Checklist for E-Commerce Sites</b></a></p> <div class="post-content" align="justified"> 	<p>Answering a question on <a href="http://www.wickedfire.com">Wickedfire</a> here.</p> <p><strong>If you own an <a href="/from-affiliate-to-e-commerce-mogul-the-real-secrets-to-e-commerce/">Ecommerce</a> site and don&#8217;t know where to begin on the SEO go through this check list. In total, it&#8217;ll cost less than $500.</strong></p> <p>1. Signup with all related forums. Put your site in the footer links and go through answering product related questions on a weekly basis.</p> <p>2. Create a free OSCommerce and Zencart template related to your parent niche (if you sell CDs make a music template), insert your link on it and distribute it on template<br /> directories and their repositories.</p> <p>3. Create an articles section on your site and put in a form allowing people to submit articles. Email hobby blogs in your niche asking to use some of their particularly good posts in exchange for a link back in the article. This will make them aware of your site and they might even link to you in future posts when talking about a particular product.</p> <p>4. Steal your competitors articles and product reviews and do article distribution.</p> <p>5. Create a blog on the site and give out manufacturer coupon codes regularly. This will sometimes help with getting negative results. Post those coupons on item #1.</p> <p>6. Put all your products in Google Products (froogle/base). This will sometimes help with getting negative results.</p> <p>7. Browse Google Products for small ecom sites with no reviews and similar products and link exchange on a separate automated link exchange script on a separate page.</p> <p>8. Make sure you optimize your onsite seo. I assume you know how to do this.</p> <p>9. Download, convert to html, and attach all the product manuals to each individual product. Link back to the product on each manual. This will give you more pages for indexing and catch a lot more longtail keywords.</p> <p>10. Spam the fuck out of Yahoo answers and similar.</p> <p>11. Directory submit! It may not work well for other sites of yours but ecommerce sites are almost always welcome in directories.</p> <p>12. Customize a nifty and unique toy style item with your logo on it and mail it to the most popular bloggers in your niche. Shirts and hats also work well.</p> <p>13. If you have access to the products get a webcam and pretend to be a vlogger. Review the products and post them on all the major video sites.</p> <p>14. Create autoblogs and link wheels.</p> <p>There&#8217;s more but I think that&#8217;ll keep you busy enough for now <img src='/wp-includes/images/smilies/icon_smile.gif' alt=':)' class='wp-smiley' /> </p> <p><strong>EDIT:</strong><br /> There was some confusion in the comments on what I meant by &#8220;Negative Results&#8221;<br /> &#8220;negative results&#8221; or &#8220;negative rankings&#8221; are the results inside of the regular results that Google puts in.<br /> Such as:<br /> Video Results<br /> Image Results<br /> News Results<br /> Product Results<br /> Blog Results<br /> They used to always appear above the regular results so we call them negative rankings because they&#8217;re less than #1. Now they tend to go between random positions. This term may change the older this article gets. </p>  	<p class="post-info"> 													 	</p> 	<!-- 		<rdf:RDF xmlns:rdf="/web/20130510105514/http://www.w3.org/1999/02/22-rdf-syntax-ns#" 	    xmlns:dc="/web/20130510105514/http://purl.org/dc/elements/1.1/" 	    xmlns:trackback="/web/20130510105514/http://madskills.com/public/xml/rss/module/trackback/"> 		<rdf:Description rdf:about="/web/20130510105514/http://www.bluehatseo.com/seo-checklist-for-e-commerce-sites/"     dc:identifier="/web/20130510105514/http://www.bluehatseo.com/seo-checklist-for-e-commerce-sites/"     dc:title="SEO Checklist for E-Commerce Sites"     trackback:ping="/web/20130510105514/http://www.bluehatseo.com/seo-checklist-for-e-commerce-sites/trackback/" /> </rdf:RDF>	--> </div> <div class="post-footer"><a href="/seo-checklist-for-e-commerce-sites/#comments" title="Comment on SEO Checklist for E-Commerce Sites">1489 Comments &#187;</a></div>									</div> 							 				<div class="post"> 					<div class="post-title"><em><a href="/category/general-articles/" title="View all posts in General Articles" rel="category tag">General Articles</a></em>04 Nov 2008 04:52 am</div> <p class="post-info"><a href="/how-to-overthrow-a-wikipedia-result/" rel="bookmark" title="Permanent Link: How To Overthrow A Wikipedia Result"><b>How To Overthrow A Wikipedia Result</b></a></p> <div class="post-content" align="justified"> 	<p>A busy ranking artist runs into this problem quite often. I ran into it again the other day and figured I might as well show my Blue Hat peeps how to overcome the same problem since its a fairly popular problem to have and there is a simple solution to it.</p> <p><strong>The Problem</strong><br /> Your site is holding a particular rank and a Wikipedia page is ranked right above it. The specific ranks don&#8217;t particularly matter, but much like Hillary Clinton in the primaries you can&#8217;t possibly live being beaten like that. You have to drop the Wikipage down a notch and you have to continue moving up.</p> <p><strong>The Simple Solution</strong><br /> The simplicity of this tactic actually depends very heavily on the Wikipedia entry. Either way they&#8217;re all very beatable, but some are easier than others. In fact as mentioned I just ran into this problem recently and I managed to knock the competitive Wikipage entirely out of the top 20 in just two days using these steps. First you need to understand why the Wikipage ranks. Most of these pages rank for 3 reasons.</p> <p><strong>1)</strong> The domain authority of Wikipedia.org.</p> <p><strong>2)</strong> Innerlinking amongst other Wikipedia entries boosting the page&#8217;s value.  &lt;- Particularly the *See Also&#8217;s</p> <p><strong>3)</strong> Inbound links from most typically blogs and forums. &lt;- <em>An observant person would not only notice the high percentage of links from blogs/forums in contrast to other types of links but a strong lack of sitewide links from any of those sites.</em></p> <p>You obviously can&#8217;t do anything about the domain authority of Wikipedia.org but understand that it&#8217;s pages are like a tripod; If you knock out one of the legs the whole thing falls (pun). Well now that you understand why it&#8217;s there right up above you like a towering fugly friend of the girl you&#8217;re trying to hit on the solution becomes obvious. Knock out reasons two and three.</p> <p><strong>Steps</strong><br /> <strong>1)</strong> Using your favorite link analysis tool (I prefer the simplistic Yahoo Site Explorer) find all the pages that link to the particular wikipedia entry that come from the wikipedia.org domain.</p> <p><strong>2)</strong> Go to each listing and find the reference to the offending Wikipage. You&#8217;ll find most of them in the See Also section or linked throughout the article. This is where the simplicity that I was talking about before comes into play. Listings such as &#8220;Flash Games&#8221; or &#8220;Election News&#8221; are easier because they&#8217;re so irrelevant. When people are searching Google for terms such as these they&#8217;re obviously wanting to find actual flash games or election news, not some faggy Wikipedia page saying what they are. The same concept applies to other Wikipages linking to them. Just because the author put the text Cat Food in the article or the See Also doesn&#8217;t mean its a relevant reference to the subject matter.</p> <p><strong>3)</strong> SLOWLY remove nearly all those bitches! Be sure to leave a good convincing reason for the removal on the editing reason. Remove as many as possible but strictly limit yourself.  I understand Blue Hatters have a tendency to overdo things but you&#8217;re just going to fuck yourself if you quickly go through each and every reference and mass delete them. If you don&#8217;t know how many you should remove, then keep it to no more than 1-2 a day. Remove the references with the highest pagerank first if you got a ranking emergency and switch IPs between each one. This will either knock out one of it&#8217;s legs or at least cripple the leg a bit. Which leaves you with my match and exceed philosophy.</p> <p><strong>4)</strong> Find all the blogs and forums that link to that Wikipage and go drop a link in as many of them as you can. Match and exceed. <img src='/wp-includes/images/smilies/icon_smile.gif' alt=':)' class='wp-smiley' />  I&#8217;m not going to dive into the nofollow talk on this one or talk about the benefits of links via blog comments. Just realize your goal in this instance isn&#8217;t to get more links it&#8217;s to get your link on the same pages that link to the Wikipage. As mentioned above you&#8217;ll be dealing mostly with blogs and forums, you&#8217;re in the same niche as the topics they&#8217;re talking about obviously and you probably won&#8217;t have any sitewide links to deal with so you won&#8217;t have to go through any link begging pains.</p> <p><strong>5)</strong> Try to drop your link into the article. This is common sense.</p> <p><strong>Side Note</strong><br /> Wikipedia&#8217;s domain authority isn&#8217;t something &Yacute;0µ should be entirely worried abouṪ. They&#8217;re site and µrl structure actually ß&Ecirc;comes favorable to help deaden some of the heightening factors.</p> <p><strong>OH FYI! There is now a Printer Friendly link on every post on Blue Hat by popular demand</strong> </p>  	<p class="post-info"> 													 	</p> 	<!-- 		<rdf:RDF xmlns:rdf="/web/20130510105514/http://www.w3.org/1999/02/22-rdf-syntax-ns#" 	    xmlns:dc="/web/20130510105514/http://purl.org/dc/elements/1.1/" 	    xmlns:trackback="/web/20130510105514/http://madskills.com/public/xml/rss/module/trackback/"> 		<rdf:Description rdf:about="/web/20130510105514/http://www.bluehatseo.com/how-to-overthrow-a-wikipedia-result/"     dc:identifier="/web/20130510105514/http://www.bluehatseo.com/how-to-overthrow-a-wikipedia-result/"     dc:title="How To Overthrow A Wikipedia Result"     trackback:ping="/web/20130510105514/http://www.bluehatseo.com/how-to-overthrow-a-wikipedia-result/trackback/" /> </rdf:RDF>	--> </div> <div class="post-footer"><a href="/how-to-overthrow-a-wikipedia-result/#comments" title="Comment on How To Overthrow A Wikipedia Result">1371 Comments &#187;</a></div>									</div> 							 				<div class="post"> 					<div class="post-title"><em><a href="/category/general-articles/" title="View all posts in General Articles" rel="category tag">General Articles</a></em>29 Jul 2008 04:12 pm</div> <p class="post-info"><a href="/open-questions-4-deminishing-values-on-outbound-links/" rel="bookmark" title="Permanent Link: Open Questions #4 - Diminishing Values On Outbound Links"><b>Open Questions #4 - Diminishing Values On Outbound Links</b></a></p> <div class="post-content" align="justified"> 	<p>I somehow missed this question from the Open Questions post and I can&#8217;t help but answer it.</p> <p>From <a href="http://www.adsenser.nl">Adsenser</a></p> <blockquote><p>I loved your SEO empire post.<br /> But I was wondering how much effect does a lot of links from a lot of indexed pages from the same domain have?<br /> I always thought that the search engines looked mainly at the number of different domain linking to you.<br /> Can you give some more info on this?<br /> Or do you use these pages to link to a lot of different domains? </p></blockquote> <p>This is a fantastic opener for a conversation on sitewide outbound links affects on other sites as well as the site itself. Which has been long debated but never cleared up, not because its too complicated just because theres so many myths its hard to work the fact from the fiction.  To be clear in my answer I&#8217;m going to refer to the site giving the link as the &#8220;host site&#8221; and the site receiving the link as the &#8220;target site.&#8221; Just so I don&#8217;t have to play around with too much terminology.</p> <p>The entire explanation of why sitewide links, main page links, subpage links, and reciprocal links work is based off a simple SEO law called Diminishing Values. It basically states that for every link whether it be recipricol, innerlink, or outbound link there is some form of consequence. Also, for every inbound link, innerlink accepted or reciprocal link there is a benefit.</p> <p><strong>SEO Law of Diminishing Values</strong><br /> Diminishing Values = sum(benefits) > sum(consequences)</p> <p>The need for the sum of the benefits to be greater than the sum of the consequences is essential because, as mentioned in my SEO Empire post there can&#8217;t be a negative relevancy for a site in relationship to a term. For example lets take the niche of cars. There&#8217;s a theoretical mass of car blogs. For the sake of the example we&#8217;ll say there are several thousand blogs on the subject of cars. Something in the industry happens that stirs all the bloggers such as SEMA having a car show or something. So all these car blogs blog about SEMA&#8217;s new car show coming out and give it a link. If these outbound links caused a consequence greater or equal to the valued benefit given to SEMA than all these blogs would drop in value as per the topic, cars. Thus the mass affect would be that of a negative relevancy, therefore sites with no relevancy but contain topic links would by all theory rank higher than the general census of on topic sites.</p> <p>So the notion of an outbound link diminishing your sites value in equal proportion is just complete bubkiss and obviously not the way things actually work. Even if it was true and there was a compensation for on site SEO when an event in a niche happens the site hosting the event wouldn&#8217;t just rise in the rankings it would propel everyone else downwards causing more turbulence in the SERPS than what happens in actuality with just their site rising. It&#8217;s just simple SEO Theory 101, but sadly a lot of people believe it. There&#8217;s also a lot of sites that absolutely won&#8217;t link to any sites within their topic in fear that their rankings will suddenly plummet the moment they do. They&#8217;re under the greedy impression that they&#8217;re somehow hording their link value and that is in some way benefiting them. So with the assumption that an outbound link gives much more value to its target than it diminishes from its host everything in a sense balances out and outbound links become much less scary. This of course in no way says that the consequence to the host is a diminishment of any sort. It&#8217;s entire consequence could be 0 or as a lot of other people believe +X (some people think on topic outbound links actually adds to your sites relevancy). I haven&#8217;t personally seen one of my sites go up in rank after adding an outbound link but I&#8217;m open to the idea or to the future of the concept being reality.</p> <p><strong>I Practice What I Preach</strong><br /> The Law of Diminishing Values is one of the reasons why BlueHatSEO is one of the only SEO blogs that has all dofollow comments as well as top commentators plugin on every page. <strong>Your comments will not hurt my rankings</strong>..I&#8217;ll say that one more time <strong>Your comments will not hurt my rankings</strong>. Whewww I feel better <img src='/wp-includes/images/smilies/icon_smile.gif' alt=':)' class='wp-smiley' /> </p> <p><strong>Back To The Question</strong><br /> Before we get into the meat of the question we&#8217;ll take a small scale example that we should all know the answer to.<br /> <strong>Q:</strong> If a host site writes an automated link exchange script that automatically does thousands of link exchanges and puts those links on a single subpage and all the target sites also have their link exchange page setup the same way on a subpage. Will the host site gain in value?</p> <p><strong>A:</strong> I&#8217;ll tell you straight up from personal experience. Yes it does. It&#8217;s simple to test if you don&#8217;t believe me go for it yourself</p> <p>Now we&#8217;ll move up to a much larger scale with a specific on topic example using sitewide links.<br /> <strong>Q:</strong> If you own two 100k+ page lyric sites with lots of inbound links and very good indexing ratios, will putting a sitewide link to the other site on both raise both in value or keep them both the same?</p> <p><strong>A:</strong> Also from my personal experience, yes both will not only raise in value but they will skyrocket in value by in the upwards of 50% which can result in much higher rankings. Likewise this example can be done with any niche and any two large sites. Cross promote them with sitewide links between the two and see what happens. The results shouldn&#8217;t be surprising.</p> <p>Now, on the large scale to the meat of the question.<br /> <strong>Q:</strong> If these two lyrics site cross compared all their inbound links from other sites and managed to get all the sites that link to lyric site A to also link to lyric site B to the point at which each increased in links by 100k (same as the number of increased links would of been with a sitewide link between the two) would both sites increase in value more-so than if they did the sitewide link instead?</p> <p><strong>A:</strong> Yes absolutely. This is a bit harder to test, but if you&#8217;ve been building an SEO Empire and each site&#8217;s inbound links are from your own sites than it becomes quite a bit easier to test and I&#8217;m certain you&#8217;ll find the results the same as I did.</p> <p><strong>Conclusion</strong><br /> <strong>On a 1:1 ratio on a generalized population of relevant links vs non-relevant inbound links from separate domains/sites are still more effective than a sidewide link of the same magnitude. However! A sitewide link does benefit both sites to a very high degree. Just not to the degree that lots of other sites can accomplish.</strong></p> <p>Sorry that question took so long to answer. I didn&#8217;t just want to give you a blank and blunt answer. I wanted to actually answer it with logic and a reasoning that hopefully leads to an understanding of the ever so important WHY. </p>  	<p class="post-info"> 													 	</p> 	<!-- 		<rdf:RDF xmlns:rdf="/web/20130510105514/http://www.w3.org/1999/02/22-rdf-syntax-ns#" 	    xmlns:dc="/web/20130510105514/http://purl.org/dc/elements/1.1/" 	    xmlns:trackback="/web/20130510105514/http://madskills.com/public/xml/rss/module/trackback/"> 		<rdf:Description rdf:about="/web/20130510105514/http://www.bluehatseo.com/open-questions-4-deminishing-values-on-outbound-links/"     dc:identifier="/web/20130510105514/http://www.bluehatseo.com/open-questions-4-deminishing-values-on-outbound-links/"     dc:title="Open Questions #4 - Diminishing Values On Outbound Links"     trackback:ping="/web/20130510105514/http://www.bluehatseo.com/open-questions-4-deminishing-values-on-outbound-links/trackback/" /> </rdf:RDF>	--> </div> <div class="post-footer"><a href="/open-questions-4-deminishing-values-on-outbound-links/#comments" title="Comment on Open Questions #4 - Diminishing Values On Outbound Links">694 Comments &#187;</a></div>									</div> 							 				<div class="post"> 					<div class="post-title"><em><a href="/category/general-articles/" title="View all posts in General Articles" rel="category tag">General Articles</a></em>09 Dec 2007 06:15 pm</div> <p class="post-info"><a href="/quick-answers-2-the-word-of-the-day-is-class-cunt-ip/" rel="bookmark" title="Permanent Link: Quick Answers #2 - The Word of The Day Is Class-Cunt IP"><b>Quick Answers #2 - The Word of The Day Is Class-Cunt IP</b></a></p> <div class="post-content" align="justified"> 	<p>Now that I put the dreaded C-word in the title mine won&#8217;t be the only office in the nation calling it Class-Cunt ips. Watch, you&#8217;ll catch yourself doing it and frankly you deserve it. <img src='/wp-includes/images/smilies/icon_smile.gif' alt=':)' class='wp-smiley' />  To make the transition into a technopotty mouth easier with a handy mnemonic: <strong>A</strong> <strong>B</strong>ig <strong>C</strong>unt <strong>D</strong>rowns <strong>E</strong>asier (E is incase we ever make that switch the government keeps rambling on about).</p> <p>I probably get more questions about my distribution of IPs than any other type. Frankly I can answer it in one word, <u>evenly</u>. But once again hitting up our <a href="/open-questions/">Open Questions</a> post here&#8217;s a question that I think best illustrates the topic.</p> <p>This one is from <a href="http://www.slayerment.com">Quinton Figueroa</a></p> <blockquote><p> 1. For each domain do you split your subdomains up in multiple C Class IPs or do they all stay on 1? Does it depend?</p> <p>2. For each domain do you link from your subdomains to other subdomains or do you keep each one as its own stand alone “site”?</p> <p>3. Do you set up in the 100’s of subdomains or in the 1,000’s of subdomains (or maybe more) per domain?</p> <p>Appreciate the help man, you kick ass! </p></blockquote> <p>Google doesn&#8217;t penalize a site because of the other sites on the same IP or class. I say this with confidence because even though Matt Cutts publicly said it in one of his video dialogs I still researched it myself to make damn sure (you can thank me later ionhosting). I also haven&#8217;t seen any evidence that the other search engines are any different. So I speak the same answer whether I&#8217;m talking about one site having a different IP than another or a subdomain having a different IP than the main domain. It&#8217;s all under the same point of reference, but to address the question directly what&#8217;s the one primary reason why a subdomain has a different IP than a main domain? Thats right, it&#8217;s on a different server.</p> <p><strong>Side Track</strong><br /> BTW when people say a statement like, &#8220;I haven&#8217;t seen any evidence&#8221; it usually means they haven&#8217;t LOOKED at any evidence. For future reference, give statements like that about as much authority as a one legged security officer. Do your own research.</p> <p><strong>Back On Track</strong><br /> If there is no penalty for sites being on the IP and there is no explicit reward for being on separate IPs than all thats left is two small benefits of 1. If your sites are black hat it makes it harder to track all them down. 2. The links appear to be more natural between two sites if they are on separate IPs (whether or not this is an actual benefit or not remains to be seen). So whole IP diversification business boils down to costs vs financial reward. So while in the past I&#8217;ve been very cautious of my own IP dispersement, which was only in part because during that period I was able to acquire IPs very cost efficiently, since I have lessened my efforts. The rewards vs the costs just aren&#8217;t there enough to invest any worry into  the matter. So my answer is simply &#8220;evenly.&#8221; <strong><u>Use what you got.</u> </strong>If you get a server and it gives you 10 free ips. Use them all and just distribute your sites amongst them. You won&#8217;t regret it and at the same time you wouldn&#8217;t see any explicit benefits from dumping a bunch of extra money every month into more ips. The money is obviously better spent on things thats make more revenue such as domains and servers. Even if you had unlimited IPs how would you end up distributing them? Evenly&#8230;</p> <p>To be perfectly clear, even though I take IP distribution with a grain of salt it doesn&#8217;t mean I take nameserver distribution lightly and the same applies to domain registration info. In fact I&#8217;d say the one exception to the IP carefree rule is if you happen to write a blog teaching people how to bend over Google like a Japanese whore. <img src='/wp-includes/images/smilies/icon_smile.gif' alt=':)' class='wp-smiley' />  I mention it, because I know some of you do. In which case be very careful about what sites you allow others to see. Throwing a few decoys out also doesn&#8217;t hurt because &#8220;do no evil&#8221; policies don&#8217;t apply to profit risks. Paranoia? For a year and a half yes, after Oct 21st of this year. No. You may not get it, but someone somewhere just shit their pants. So feel free to giggle anyways.</p> <p>As for questions 2 and 3 if you would of asked me a year ago I would of had a completely different response. Yet the basic principle still remains. I talked about this topic to great depth in my <a href="/seo-empire-part-1/">SEO Empire Part 1</a> post. Reread the section where I talk about the <u>One Way Street Theory</u>. The decision on how many subdomains as well as whether or not they should be orphan subdomains or innerlinked is a decision I make by asking whether or not those subdomains would be of benefit to the main domain. If they are of a benefit to it than i establish a relationship between the two (ie a link either one way or exchanged). If they aren&#8217;t than I keep the subdomains orphan. BTW the term Orphan subdomain or Orphan Subpage was a term coined by an obnoxious troll here. I kinda liked it so I kept it. It means the subdomain has no relationship with the main domain or any other pages or subdomains of the site. Watch out for innerlinking between subdomains though. Think in terms of sites who do it effectively and sites that don&#8217;t. If your innerlinking in a way that mimics About.com or similar than great. If your innerlinking in a way that say Blog Solution or something would, for the sake of link building to each subdomain, I&#8217;d advise against it for footprint reasons and for god sakes if you&#8217;re hosting a blackhat generated site on a white hat domain don&#8217;t even consider it!</p> <p><strong>Do&#8217;s and Don&#8217;ts of Subdomains.</strong><br /> <strong>Do</strong> create subdomains for the purpose of exploiting an established domains domain authority. - I&#8217;ve talked a lot about software related sites. I think they&#8217;re a great and easy way to build domain authority. Anything related can be thrown into a subdomain. I got a couple general sites that have great domain authority and anything i throw up on it does well in the SERPS almost instantly. I make sure to not over do it and it works out very well for me.</p> <p><strong>Don&#8217;t</strong> create subdomains to save on domain costs. - It&#8217;s less than ten dollars a year for fuck sake. Don&#8217;t risk trashing a $20/day site and its authority that it took you a year or two to establish to save $10/year. </p>  	<p class="post-info"> 													 	</p> 	<!-- 		<rdf:RDF xmlns:rdf="/web/20130510105514/http://www.w3.org/1999/02/22-rdf-syntax-ns#" 	    xmlns:dc="/web/20130510105514/http://purl.org/dc/elements/1.1/" 	    xmlns:trackback="/web/20130510105514/http://madskills.com/public/xml/rss/module/trackback/"> 		<rdf:Description rdf:about="/web/20130510105514/http://www.bluehatseo.com/quick-answers-2-the-word-of-the-day-is-class-cunt-ip/"     dc:identifier="/web/20130510105514/http://www.bluehatseo.com/quick-answers-2-the-word-of-the-day-is-class-cunt-ip/"     dc:title="Quick Answers #2 - The Word of The Day Is Class-Cunt IP"     trackback:ping="/web/20130510105514/http://www.bluehatseo.com/quick-answers-2-the-word-of-the-day-is-class-cunt-ip/trackback/" /> </rdf:RDF>	--> </div> <div class="post-footer"><a href="/quick-answers-2-the-word-of-the-day-is-class-cunt-ip/#comments" title="Comment on Quick Answers #2 - The Word of The Day Is Class-Cunt IP">156 Comments &#187;</a></div>									</div> 							 				<div class="post"> 					<div class="post-title"><em><a href="/category/general-articles/" title="View all posts in General Articles" rel="category tag">General Articles</a></em>11 Sep 2007 06:12 am</div> <p class="post-info"><a href="/seo-empire-part-1/" rel="bookmark" title="Permanent Link: SEO Empire - Part 1"><b>SEO Empire - Part 1</b></a></p> <div class="post-content" align="justified"> 	<p><strong>Podcast Versions:</strong></p> <p><strong>Printer Friendly: <a href="/seoempirepart1.html">Part 1</a></strong></p> <p>This is exactly how I make money online&#8230;</p> <p>This blog has a lot of great tips and techniques to help the average webmaster break beyond their barriers. However they are nothing more than skillsets. Skillsets are worthless without direction. For that reason before I&#8217;m done with the missions I want for this hobby (blog) I want to lay down 4 corner stone strategy posts. This is the second behind my <a href="/serp-domination/">SERP Domination</a> post which taught the power behind numbers. As mentioned in my <a href="/blue-hat-technique-18-log-link-matching/">Log Link Matching</a> article every technique on this blog interconnects like a well connected puzzle and fits together perfectly to form an ultimate SEO strategy. This is that strategy. In that spirit every post before this one builds up to this post and every post after is a follow-up to it. By now you hopefully have had time to browse through the archives and digest all the past posts. This will give you the necessary skillset and more importantly mindset to put all this into practice.  I&#8217;ve always preached that there is no rules in SEO only loosely enforced guidelines. So it&#8217;s time to take the Jalape�o peppers the rest of the industry have given us out of our asses and prepare to tear this shit up. Its time to build our own <strong>SEO Empire</strong>.</p> <p> <a href="/seo-empire-part-1/#more-240">(more&#8230;)</a> </p>  	<p class="post-info"> 													 	</p> 	<!-- 		<rdf:RDF xmlns:rdf="/web/20130510105514/http://www.w3.org/1999/02/22-rdf-syntax-ns#" 	    xmlns:dc="/web/20130510105514/http://purl.org/dc/elements/1.1/" 	    xmlns:trackback="/web/20130510105514/http://madskills.com/public/xml/rss/module/trackback/"> 		<rdf:Description rdf:about="/web/20130510105514/http://www.bluehatseo.com/seo-empire-part-1/"     dc:identifier="/web/20130510105514/http://www.bluehatseo.com/seo-empire-part-1/"     dc:title="SEO Empire - Part 1"     trackback:ping="/web/20130510105514/http://www.bluehatseo.com/seo-empire-part-1/trackback/" /> </rdf:RDF>	--> </div> <div class="post-footer"><a href="/seo-empire-part-1/#comments" title="Comment on SEO Empire - Part 1">1401 Comments &#187;</a></div>									</div> 							 				<div class="post"> 					<div class="post-title"><em><a href="/category/general-articles/" title="View all posts in General Articles" rel="category tag">General Articles</a></em>02 Jul 2007 09:52 pm</div> <p class="post-info"><a href="/how-to-dupe-content-and-get-away-with-it/" rel="bookmark" title="Permanent Link: How To Dupe Content And Get Away With It"><b>How To Dupe Content And Get Away With It</b></a></p> <div class="post-content" align="justified"> 	<p>Let&#8217;s do one more post about content. First, consider <a href="http://googlewebmastercentral.blogspot.com/2006/12/deftly-dealing-with-duplicate-content.html">Google&#8217;s Webmaster Blog</a>&#8217;s post dispelling common duplicate content myths as a prerequisite read. Do I always trust what Google&#8217;s public relations tells me? Absolutely not, but it does confirm my own long standing protests against people who perpetuated the paranoia about duplicate content. So it makes a good point of reference.</p> <p>The most common myth ensue with the paranoia is, &#8220;anytime I use content that is published somewhere else, I am sure to fall victim to duplicate content penalties.&#8221; This of course is bunk because for any specific terms related to an article you can show me I can find you 9 other sites that ranks for its terms that aren&#8217;t necessarily supplemental and full of penalties. However there is no doubt that there really is a duplicate content penalty. So we&#8217;ll discuss ways around it. One of my favorite parroted phrases is, &#8220;It&#8217;s not what content you use. It&#8217;s how you use it.&#8221;  So we&#8217;ll start with formatting.</p> <p><strong>Here Is Some Spammy Text</strong><br /> Welcome to spam textville. This is just a bunch of spammy text. Text to fill and spam the streets. This is horrible spam text filled content that will surely get my spam site banned. Spam spam spam. It&#8217;s not food it&#8217;s text. Spammy text. I copied this spam text all over my site and others are copying it for their spammy text sites. I can&#8217;t believe I&#8217;m keyword stuffing for the words spammy text.</p> <p>Alone in paragraph form this text is very easy to detect as spam and being autogenned. So the classic SEO ideology of &#8220;well written article style paragraphed text does well&#8221; gets thrown out the window with this example. However, since I would love nothing more than to rank for the term &#8220;Spammy Text&#8221; and this is all the content available to me I have to abandon the idea of keyword stuffing and find some new formats to put this text in that search engines will find acceptable.</p> <p><strong>How about an Ordered List?</strong></p> <li>Welcome to spam textville.</li> <li>This is just a bunch of spammy text.</li> <li>Text to fill and spam the streets.</li> <p><em>Lists and bulleted points work very well because the text enclosed is meant to be very choppy, short, and contain repetition such as My goals are, The plan is, Do this..etc. etc.  If the common ordered list is formatted as such, than we by all right can do the same.</em></p> <p><strong>What about presenting it as user contributed?</strong></p> <h3><strong>Comments (3)</strong></h3> <p><strong>John Doe:</strong><br /> Spam spam spam.</p> <p><strong>Jane Doe:</strong><br /> I copied this spam text all over my site and others are copying it for their spammy text sites.</p> <p><strong>John Deer:</strong><br /> Spammy text.</p> <p><em>How many of you readers have left complete crap in my comments? I&#8217;m not banned or penalized yet.  <img src='/wp-includes/images/smilies/icon_smile.gif' alt=':)' class='wp-smiley' />  Faking user contributed material works great because since it&#8217;s outcome is unpredictable therefore you can do virtually anything with it and get away. Including but not limited to inner linking.</em></p> <p><strong>Mary Jane:</strong><br /> I saw this wicked article about this on Eli&#8217;s blog subdomainspam.spammydomain.com/spammysubpage.html check it out!<br /> <strong><br /> Break It Up Into Headings</strong><br /> <strong><br /> <h3>Heading 1</h3> <p></strong><br /> Welcome to spam textville. This is just a bunch of spammy text.</p> <p><strong><br /> <h3>Heading 2</h3> <p></strong><br /> Text to fill and spam the streets. Spam spam spam. It&#8217;s not food it&#8217;s text.</p> <p><em>All the keywords are there its just no longer spammy because its been broken up properly into nice little paraphrases. Once again, standardized = acceptable.</em></p> <p><strong>Change The Format</strong><br /> What about PDF&#8217;s? They may not support contextual ads very well but they most certain can cointain affiliate links. The engines also tend to be quite lenient on them and redundant text. For more information read my <a href="/links-through-document-links/">Document Links</a> post.</p> <p><strong>Let&#8217;s Move On</strong><br /> So now that we can format our text to avoid the penalties what if we attempt to side step them all together? I talked about how to swap titles out using a thesaurus and IMDB data in my <a href="/black-hole-seo-the-real-desert-scraping/">Desert Scraping</a> post. So I won&#8217;t talk too much about it, but definitely consider doing some research on <a href="http://www.digeratimarketing.co.uk/2007/04/27/exploiting-lsi-to-rank-higher">exploiting LSI</a> in this matter.</p> <p><strong>How about scraping the right content?</strong><br /> Heavily syndicated content works well for duping and it has the added bonus of being exclusively high quality. For instance I sometimes like to snag shit from the good ol&#8217; AP. It&#8217;s not the smartest legal move but seriously, who&#8217;s going to deeply investigate and do anything about it? In such an event its always an option to just remove the article upon receipt of the CDC letter.</p> <p>All in all, theres plenty you can do to dupe content and get away with it. It&#8217;s a pretty open game and theres a lot out there.</p> <p><strong>Have Fun</strong> </p>  	<p class="post-info"> 													 	</p> 	<!-- 		<rdf:RDF xmlns:rdf="/web/20130510105514/http://www.w3.org/1999/02/22-rdf-syntax-ns#" 	    xmlns:dc="/web/20130510105514/http://purl.org/dc/elements/1.1/" 	    xmlns:trackback="/web/20130510105514/http://madskills.com/public/xml/rss/module/trackback/"> 		<rdf:Description rdf:about="/web/20130510105514/http://www.bluehatseo.com/how-to-dupe-content-and-get-away-with-it/"     dc:identifier="/web/20130510105514/http://www.bluehatseo.com/how-to-dupe-content-and-get-away-with-it/"     dc:title="How To Dupe Content And Get Away With It"     trackback:ping="/web/20130510105514/http://www.bluehatseo.com/how-to-dupe-content-and-get-away-with-it/trackback/" /> </rdf:RDF>	--> </div> <div class="post-footer"><a href="/how-to-dupe-content-and-get-away-with-it/#comments" title="Comment on How To Dupe Content And Get Away With It">141 Comments &#187;</a></div>									</div> 							 				<div class="post"> 					<div class="post-title"><em><a href="/category/general-articles/" title="View all posts in General Articles" rel="category tag">General Articles</a></em>13 Jun 2007 07:41 pm</div> <p class="post-info"><a href="/how-to-build-your-own-squirt/" rel="bookmark" title="Permanent Link: How To Build Your Own SQUIRT"><b>How To Build Your Own SQUIRT</b></a></p> <div class="post-content" align="justified"> 	<p>LOL, be truthful. Did you honestly see this post coming? People wanted to know how the tool works, but I think I can do you all one better. I&#8217;ll explain in detail how exactly it works and how to build one for yourself so you can have your very own, hell one to sell if you wanted. Would you guess there&#8217;s a demand for one? Haha Sure why not? I can&#8217;t think of a single good reason why I shouldn&#8217;t (I never considered money a good enough reason to not help people). However I would like to ask a small favor of you first. Please go to <a href="http://www.robstool.com"><strong>RobsTool.com</strong></a> and subscribe. Throughout this month we are adding a new section called &#8220;The Lab&#8221; inside the tool where we are going to be hosting a multitude of crazy and wacky SEO tools that you&#8217;ve probably never thought could exist. Even if you don&#8217;t have a membership please subscribe anyways so you can get some cool ideas for tools to build yourself. That out of the way, lets begin. <img src='/wp-includes/images/smilies/icon_smile.gif' alt=':)' class='wp-smiley' /> </p> <p><strong>The Premise</strong><br /> <a href="http://squirt.robstool.com">SQUIRT</a> works off of a very, very simple premise. Over the span of the months you promote your websites from their infancy to well aged mongers, you make dozens of small decisions daily. All the tool does is mimic as many of those decisions as possible and boil them down to a small yes or no; true or false; boolean expression. This is just very basic AI (Artificial Intelligence) and decision making based on some data. There really is nothing complex about it. Think about the first time you promoted a website in the search engines. You looked at what you considered some factors in ranking. You saw what your competitors had that you didn&#8217;t. What was your first initial reaction? You likely thought, &#8220;how can I get what they have?&#8221; A script can&#8217;t do this of course. This is a human reaction that can&#8217;t be duplicated by a machine. However, now think about the second, fifth, tenth website you&#8217;ve promoted. Once again you looked at what your competitors had that you didn&#8217;t. From there you may have noticed your mindset changed from &#8220;how can I get it&#8221; to something like, &#8220;how did I get it before?&#8221; This a machine can do! Experience just made the difference between a decision that needs to be made and a predefined decision that sets an orchestrated path. I know this all seems overwhelming, but I assure you its all really, really simple. The trick is, just build a tool that would do whatever you would do, based on the current situation. The situation of course can be defined by what we all know and study everyday of our professional SEM lives, Search Engine Factors. So the best place to begin is there.</p> <p><strong>A List Of Factors</strong><br /> Since the tool will make its decisions based on stuff you consider to be factors search engines use to rank your sites, making a list of all the known factors is a big help. Sit and write down every search engine factor you can think of. Break them down to specifics. Don&#8217;t just write &#8220;links.&#8221; Write Link Volume, Link quality, links on unique domains, percentage of links with my anchor text..etc. The <a href="http://squirt.robstool.com">SQUIRT</a> utility I released looks at 60 separate factors. So at least you have a general goal to shoot for. Come up with as many factors as possible. Once you got a good clean list of factors start figuring out a proper way to measure each of them.</p> <p><strong>Factor Measurement</strong><br /> How many times today did you go to a search engine and type in link:www.domain.com? That is a measure of a factor. How about site:www.domain.com? Thats another. Each of those are a factor that when explored by either going to your own site, or going to the search engines can result in some sort of figure or number you can use to calculate how your site fairs in comparison to the sites currently ranking. Let&#8217;s use an example. You go to google and you search for your keywords that you are wanting to rank for. You make a list of all the sites in the top 10 and separately do a link: command for each of their domains. You then take all those figures and average them out. That gives you a rough idea of how much &#8220;link volume&#8221; you will need to get into the top 10. You then do a link: command on your own site to see how close your site is to that figure. From there you can make a decision. Do I need to work on increasing my link volume factor or not? You just made a boolean decision based on a single factor using data available to you. It probably took you a good 5 minutes or more to make that decision. Where as a script could of made that decision for you in less than a second. Now I know you&#8217;re all just as much of a computer nerd as I am, so I don&#8217;t have to preach to you about the differences in efficiency between yourself and a machine, but at least think about the time you would compound making these very simple decisions for each and every factor on your list for each site you own. There goes a good five hours of your work day just making the predictable yes or no decisions on what needs to be done. This sounds ridiculous of course, but I&#8217;d be willing to bet that at least 90% of the people reading this post right now spend most of their time doing just that. Ever wonder why most search marketers just trudge along and can&#8217;t seem to get anywhere? Now you know.</p> <p><strong>Making The Decisions</strong><br /> Okay so let&#8217;s take an example of a factor and have our script make a decision based on it. We&#8217;ll look at the anchor text saturation factor. We look at our inbound links and find all the ones that contain our anchor text versus the ones that don&#8217;t and only contain some similar words somewhere else on the page(most other documents). We then make a percentage. So we&#8217;ll say after looking at it 30% of our inbound links contain our exact anchor text. We then look at our competition. They seem to average 40%. Therefore our script needs to follow a promotional plan that increases our percentage of links that contain our exact anchor text. Very good, we&#8217;ll move along. Next we&#8217;ll look at inbound links that don&#8217;t contain our anchor text but contain our keywords somewhere in the document. Looking at our site we seem to average about 70%. Our competition seems to average about 60%. So we are doing much better than our competition. Therefore our script doesn&#8217;t need to increase our links that doesn&#8217;t contain our exact anchor text but do have relevant text. Wait, did I just contradict myself? These two factors are complimentary. So the more our tool increases one factor the further the other one drops. Wouldn&#8217;t this throw our promotion through some sort of infinite loop? Yes I did contradict myself and Yes it would put our promotion through an infinite loop. This is called on going promotion. The fact is THEY rank YOU don&#8217;t. Therefore you have to keep improving the factors you lack until you do rank; even if they seem to almost contradict each other. By the end of the analysis your script ends up with a long list of DO&#8217;s and a long list of DON&#8217;T NEED AT THIS TIME. So now all you have to do is use your own experience and your own site network to make all the DOs happen to the best of it&#8217;s abilities.</p> <p><strong>Establishing A Promotional Plan</strong><br /> So now that we have a list of all the stuff we need to improve with our site we can program our SQUIRT script to just simply do whatever it is we would do to compensate for our site&#8217;s shortfalls. To give you a better idea of how to do this and how SQUIRT handles these exact situations, I&#8217;ll take 3 example factors and let you know exactly what it does when you hit that submit button. However keep in mind, no matter how much information you gather on each site, every promotional situation is unique and requires a certain amount of human touch. The only thing you can do is define what you would do in the situation if you had no prior knowledge of the site or any extenuating circumstances. Also keep in mind that you have to remain completely hands off. You don&#8217;t have ftp access to their site, you can&#8217;t mess with their design. So anything you do has to be completely offsite SEO. Also, anything you do can&#8217;t hurt the site in anyway. Every plan needs to be 100% focused on building, and any method of promotion that may possibly cause problems for them, even if you plan on only running throw away black hat sites through the tool, needs to be 100% positive. So if you want to go get links. You need to do it within your own network of sites. You can&#8217;t go out sending spam comments or anything. </p> <p><strong>Page Rank</strong><br /> <strong>Your Site:</strong> PR 2<br /> <strong>AVG Competitor:</strong> PR 3<br /> <strong>Decision:</strong> Increase Page Rank<br /> <strong>The Plan:</strong> Create a network of very large sites. Since pagerank can be gathered internally just as easily as from external sources. Than you need to build a network of sites with lots and lots of indexed pages. Take a look at the current volume of sites you plan on running through your SQUIRT tool and decide how big you need to build your network before hand. When we decided to make SQUIRT public, even though not all the sites would require a Page Rank increase we knew a TON would. We launched the tool with the capability of handling 500 members. So we knew that 500 members, submitting 10 sites/day with each link needing to hold on a single page for at least a week, could result in needing 150,000 links available to us each week. If each link was on a page with a PR 1 than each page would send a tiny page rank increase to the target link. Likewise if each indexed page had a PR1 and we put five links up on each page, than each page would give out even more page rank through the links. There is a point of saturation of course. We decided 10 was good for each page. So we could get the maximum amount of pagerank sucked out of each indexed page while maintaining the highest possible volume of links we could spare. So if we built a network of sites that contained a total of about 1,000,000 pages indexed(you heard me), each averaging a PR1. Than we could transfer enough page rank to 150,000 links/week to constitute a possible bump in page rank to each link. For your own personal SQUIRT of course you don&#8217;t need nearly that volume. However make sure to preplan ahead because even if you make a 1 million page site, it doesn&#8217;t mean you will get 1 million pages in the index. So may have to build quite a few very large sites to reach your goals. This of course takes time and lots of resources.</p> <p><strong>Anchor Text</strong><br /> <strong><strong>Your Site:</strong> 30%<br /> AVG Competitor:</strong> 40%<br /> <strong>Decision:</strong> We need to increase the number of links that contain our exact anchor text.<br /> <strong>The Plan:</strong> Now since the tool can&#8217;t directly affect the site than we can&#8217;t exactly go to every inbound link the site has gotten and figure out a way to get them to change the anchor text. There are just too many ways to gain links and its completely unreasonable to attempt. So the only way to increase the anchor text match percentage is to increase the total number of links to the site and then have them all match the anchor text. This is where you need to queue up the blogs. All you have to do is create a bunch of blogs all over, and take steps to increase the chances of each individual post getting indexed. Than you can fill the blogs with the anchor text of the site. This however is no easy task when dealing with a large volume. Since you need plenty of authority you will need to get accounts on all the major blog networks. Remember, the average blog usually has less than 5 posts/day so you will need to compensate in sheer volume of actual accounts. These will also need to be maintained and anytime one gets banned another needs to be automatically created to take it&#8217;s place. Those of you using the tool have probably already noticed links from these places showing up in your logs and Technorati links. Since we knew so many links/day would be required we had to create an absolutely HUGE network of blogs on various places as well as the automated system to create new ones if another gets buried. Once these links have been dispersed over time, the anchor text percentage will start to rise.</p> <p><strong>Deep Indexing</strong><br /> <strong>Your site:</strong> 3 pages in the index.<br /> <strong>Crawl Stats:</strong> 10+ subpages identified<br /> <strong>Decision:</strong> Need to get more bots to the subpages of the submitted site.<br /> <strong>The Plan:</strong> So the script grabs the main page of the site and immediately sees more subpages available than are currently indexed in the search engines. This lets us know that the submitted site is having a hard time being properly deep indexed. So this is when we queue the Roll Over Sites to help get some SE bots to these subpages. There is one problem however. When dealing with my own sites it&#8217;s fine to scrape the content then redirect as detailed in the strategy that I talked about in the <a href="/power-indexing-tips/">Power Indexing</a> post. However since this tool will be a public one I can&#8217;t scrape peoples content because there is the odd chance that my rollover site may temporarily outrank their actual site and it could draw some anger from people who don&#8217;t know what it is. Remember the rule. The tool can&#8217;t harm the site in any way. So we had to go another route. Instead we pulled from a huge list of articles and just used that as the content then pushed the spiders to those pages then when they got indexed, redirected them to the site. These of course don&#8217;t show up as links so it&#8217;s all backend, however it does a fantastic job of getting subpages indexed. Since Rollover Sites use actual content than there is no problem making them absolutely huge. Therefore you don&#8217;t need a very large network of them to push a very large amount of bots. Yet at the same time you still have to follow the rule of no interference with their site. So if their site is having a hard time getting deep indexed and you can&#8217;t exactly ftp a sitemap over than you have to bring in a large network of Third Party Rolling Sitemaps. So what you do is, you create a network of sites that are essentially nothing more than generic sitemaps. You drive a lot of bot traffic to them on a regular basis and have them roll through pages that go through the tool. Once the tool has identified up to 10 subpages of the target site than it can add them to the network of third party sitemaps. The new pages go in, old pages go out(The technical term for this is a FIFO algorithm). If you have a solid enough network of third party sitemaps you can hopefully push enough search engine crawlers through them to get every page crawled before it gets pushed out. This of course is a huge problem when dealing with a large volume of sites. If we originally wanted enough power for 500 members than we knew that 500 members submitting 10 sites/day which each contained up to 10 subpages would mean we would need enough third party sitemaps to accommodate 50,000 pages/day. While the efficiency of a single third party sitemap site may be big, a massive network would be needed to push that kind of volume. It&#8217;s just beyond unreasonable. So instead, we incorporated a gapping system. So anytime there wasn&#8217;t a new page coming in and it had a chance to display a set of links to a SE bot for the second time than it would grab some older entries that were already rolled through and display them as well. So if you push enough crawl traffic through than eventually every page will theoretically get crawled.</p> <p><strong>Rinse and Repeat</strong><br /> So thats all there is to it. It&#8217;s really quite simple. As you build your SQUIRT work your way through every factor you wrote down and think about what you would do as a hands off Internet Marketer to compensate if a site didn&#8217;t meet the requirements for that particular factor. This also applies to flaws in onsite SEO. Let&#8217;s say for instance the page doesn&#8217;t have the keywords in the title tag. You can&#8217;t touch that title tag, so whats the offsite SEO equivalent to not having the keywords in the title tag? Putting them in the anchor text of course. Just keep relentlessly plugging away and build an established plan for each factor on your list. With each failure to meet a factor there is potentially a problem. With each problem there is a potential solution your script and personal site network can take care of for you. It just may require a bit of thinking and a whole lot of building. It&#8217;s tough, trust me I know <img src='/wp-includes/images/smilies/icon_smile.gif' alt=':)' class='wp-smiley' />   but it&#8217;s worth it because in the end you end up with a tool that comes close to automatically solving most of the daily problems that plague you. Here&#8217;s the exciting part. Once you start building and going through all the factors you&#8217;ll find some you probably can&#8217;t solve. Just remember, every problem has a solution. So you may just learn a few tricks and secrets of your own along the way. Shhh don&#8217;t share them. <img src='/wp-includes/images/smilies/icon_smile.gif' alt=':)' class='wp-smiley' /> </p> <p><strong>Is SQUIRT Biased?</strong><br /> ABSOLUTELY! Think about what it uses to determine the site&#8217;s standing on it&#8217;s strengths and weaknesses. If you do a link: command there is a delay in time between what the search engine shows and what actually exists that may range up to days and weeks. This causes major problems. The tool may think you need a bunch of links when it in fact you already got plenty and they just haven&#8217;t shown up yet. It may think you have a ton of links when those links were actually only temporary or you lost them before they had a chance to disappear. Essentially the tool operates off of your site&#8217;s <strong>potential SEO worth</strong>. So lets say you have an old site that you haven&#8217;t really done anything with, then you run it through your SQUIRT. The tool will stand a much better chance of making an accurate analysis, and likewise any boosts you receive in the factors will more than likely be the right ones. Therefore it will appear as if your site just skyrocketed up simply because of one little submit through the tool. When in fact the site had that sort of potential energy the whole time and it just needed a little shove to get moving. The same could be said about an established site experiencing extremely slow growth. It fairs well, maybe even in the 60%+ range, so it appears to not need very much. Then at the same time, everything the tool does do, matters very little in the large scheme of your escalated promotional campaign. Also, the tool can only focus on one site during one phase in it&#8217;s promotion at a time. So if you got a brand new site that you submit, than the tool will naturally focus more heavily on getting the site properly indexed and less on helping it gain rank through the SERPS. So if indexing methodologies don&#8217;t completely work in that particular case than it appears as if your tool didn&#8217;t do anything at all. Remember, this is only a tool, its all artificial decision making. There is no substitution for the human touch. No matter how complex or how efficient a tool you build is, there is no way it can compete without an actual human element helping to push it. All your competitors are humans. So there&#8217;s no logical reason why you can expect to ever build a tool that is the end all solution to beating them everytime. So even though you now have a really cool tool, still remember to be hardworking, smart, and efficient&#8230;never lazy. <img src='/wp-includes/images/smilies/icon_smile.gif' alt=':)' class='wp-smiley' /> </p> <p>Sorry about the long as hell post, but you guys wanted to know what the tool was doing when you clicked the button. Now you do, and hey&#8230;least I didn&#8217;t go through ALL 60 factors. <img src='/wp-includes/images/smilies/icon_smile.gif' alt=':)' class='wp-smiley' /> </p> <p><strong>Get Building</strong> </p>  	<p class="post-info"> 													 	</p> 	<!-- 		<rdf:RDF xmlns:rdf="/web/20130510105514/http://www.w3.org/1999/02/22-rdf-syntax-ns#" 	    xmlns:dc="/web/20130510105514/http://purl.org/dc/elements/1.1/" 	    xmlns:trackback="/web/20130510105514/http://madskills.com/public/xml/rss/module/trackback/"> 		<rdf:Description rdf:about="/web/20130510105514/http://www.bluehatseo.com/how-to-build-your-own-squirt/"     dc:identifier="/web/20130510105514/http://www.bluehatseo.com/how-to-build-your-own-squirt/"     dc:title="How To Build Your Own SQUIRT"     trackback:ping="/web/20130510105514/http://www.bluehatseo.com/how-to-build-your-own-squirt/trackback/" /> </rdf:RDF>	--> </div> <div class="post-footer"><a href="/how-to-build-your-own-squirt/#comments" title="Comment on How To Build Your Own SQUIRT">325 Comments &#187;</a></div>									</div> 							 				<div class="post"> 					<div class="post-title"><em><a href="/category/general-articles/" title="View all posts in General Articles" rel="category tag">General Articles</a></em>10 May 2007 11:49 pm</div> <p class="post-info"><a href="/real-seo-example/" rel="bookmark" title="Permanent Link: Real SEO Example"><b>Real SEO Example</b></a></p> <div class="post-content" align="justified"> 	<p>Every so often I get an Email from someone who instead of having a question or comment they give me a url and ask me to give them SEO advice on it. I normally don&#8217;t respond to these emails other than maybe a quick &#8220;did you have a specific question&#8221; type response. It&#8217;s not because I don&#8217;t want to or I take any offense to it, in fact its the complete opposite. Sorry to say I just don&#8217;t have the time to do full blown SEO analysis jobs for people. It&#8217;s not that I don&#8217;t want to, trust me I do, its just that I&#8217;m not one of those SEO bloggers whose career is blogging about SEO. I&#8217;m in the thick of it just like you guys are; day in and day out. I&#8217;m out there doing the techniques I talk about on this site everyday. Thats my job, and there&#8217;s no shortage of it. However, every once in awhile I&#8217;ll hit a gem. One of those unique situations that I can&#8217;t help but mole it around in my mind. One such example came to me last week by a reader here who was referred to by <a target="_blank" href="http://www.jonwaraas.com">Jon Waraas</a>(excellent blog; check out), and I think it could apply to a lot of other people in the same situation. He was kind and patient enough to allow me to publicize my response in an effort to help out others. So out of the usual context I&#8217;m going to take this example and show you all exactly what I would do in his situation.</p> <p><strong>The Situation</strong><br /> His site is going for the term &#8220;Myspace Layouts.&#8221; He already used to rank #1 for a solid amount of time. However after some time he admittedly got lazy and lost his ranking. He now still ranks in the top 10 steadily, but not quite top 5. He wants to rank number one again and was wondering if implementing my <a href="/keyword-fluffing/">Keyword Fluffing</a> and <a href="/serp-domination/">SERP Domination</a> strategies would help.</p> <p>I consider &#8220;Myspace Layouts&#8221; as a highly competitive term so this will be a great example. It&#8217;s also has the added difficulty factor of being an extremely fast growing niche; especially in just the last year. However, our mission isn&#8217;t just to take the number one rank, but to keep it intimidating for the others thinking about trying to take it themselves. So first we&#8217;ll look at what we got and then we&#8217;ll analyze what we&#8217;re up against and see if we can spot any weaknesses we can use to our advantage.</p> <p><strong>What We Got</strong><br /> Without even having to look at his site I can assume his on-site optimization is near perfect. He used to rank #1 steadily and where he&#8217;s at now he&#8217;s holding firm. Obviously, if he ranked at one point there&#8217;s no reason why he can&#8217;t rank again. So my first suggestion would be to not do a damn thing to the site itself. In my SERP Domination post I talked about how to break into the top 10 on a highly competitive niche by splitting up the site into a network of smaller content sites. In this situation he&#8217;s already in and has everything he needs to rank in the top position, so I would definitely advice against breaking up the site or making any drastic on-site SEO changes. Instead we&#8217;ll focus on off-site optimization and getting what links we need to earn that coveted spot again. Right now he has about 320,000 inbound links according to the Yahoo linkdomain: command. About 303,000 go directly to the main page. ~86,000 of his links come directly from Myspace Profiles. He also has a PR6.</p> <p><strong>What They Got</strong><br /> His top competitor has about 551,000 inbound links. 344,000 come directly from Myspace Profiles. Taking a quick look at the second and third placed competitors they are slightly less than the number one and theres nothing too notable about them. So for now we&#8217;re going to say fuck &#8216;em and not concern ourselves with what they&#8217;re doing because we know if we take the #1 site we&#8217;ll beat them as well. That after all is our main target and without extenuating circumstances they can be ignored in this case. So with that information out of the way for now, lets look at some strong determining factors and some weaknesses of both sites in respect to their rankings.</p> <p><strong>Spotting The Weaknesses and Loopholes</strong><br /> Lets analyze the math real quick. Without Myspace profile links he has 234,000 links on his own from other sites. His competitor has about 207,000. He is the clear winner in this instance which gives us a huge advantage.  However, his 86,000 links directly from people&#8217;s Myspace profiles account for only about 27% of his inbound links. While his competitor clearly dominates by having his 344,000 Myspace profile links account for a whopping 62% of his total inbound links. We now have both a strength and a weakness for each of the sites. More importantly we now know why we&#8217;re loosing. Thus, we know what loopholes we&#8217;ll need to exploit in order to win.</p> <p><strong>What Do We know?</strong><br /> By looking at both our site and the competition we know that if we can increase our links from people&#8217;s Myspace profiles in the index to at least 62% than we will win. That means we&#8217;ll have to gain about 112,000 links on Myspace Profiles. We also know that our competitor is getting these profile links the same way we are. By giving out free Myspace layouts that include a link to our sites. There is a big problem standing our way though. Since they are ranked #1 and we&#8217;re ranked lower than we can assume they are getting more traffic than we are. Therefore, they are gaining these profile links faster than we are by giving out more layouts. It&#8217;s quite the pickle.  We&#8217;ll have to do one of two things. We&#8217;ll either have to increase the value of each profile link or we&#8217;ll have to increase our volume at a much much faster rate. Neither sound like a fun solution, so we&#8217;re going to have to take a few shortcuts. One of which includes a twist on a technique I&#8217;ve already talked about, the other is an upcoming <a href="/category/blue-hat-techniques/">Blue Hat Technique</a> I&#8217;m yet to discuss. First and foremost we need the proper mindset. We can&#8217;t just try to beat this guy, we need to brutally destroy him and get him so far below us that he&#8217;ll be stuck in the same situation we are in now. It&#8217;s the only way to maintain our competitive edge. So get any thoughts of playing nice out of your head right now. They aren&#8217;t going to do you any good.</p> <p><strong>Establishing A Plan Of Attack</strong><br /> First we&#8217;ll need to do an interesting twist on my <a href="/blue-hat-technique-16-link-laundering-sites/">Link Laundering</a> technique and merge it with our <a href="/serp-domination/">SERP Domination</a> tactic. Remember when I mentioned in one of the comments that all the techniques I&#8217;ve talked about on this site fit together perfectly like a puzzle to create an ultimate ranking strategy? I wasn&#8217;t fucking around. There&#8217;s no reason why you can&#8217;t create a network of sites within subniches that launder targeted links to your main site. He already mentioned in his original email that he wanted to create a few sites based on Myspace subniches to help build link popularity to his main site. Except, knowing what we know now, he doesn&#8217;t need more links from outside sites. He needs more links from Myspace Profiles. So I&#8217;d recommend doing just that. Build several sites on Myspace subniches such as image uploaders, profile editors, webproxies..etc. However, anytime they have an opportunity to get a link on the persons profile, instead put in the url to your main site. Looking at the current scenario he&#8217;s going to need quite a few of these sites in order to catch up, I&#8217;d say about 15 that perform on the average or even a little below average. It also wouldn&#8217;t hurt to sponsor a few of these types of sites in exchange for them laundering out links to you. I know places like Myspace Web Proxies have a hard time finding and keeping converting ads on their sites, they could be a very cheap solution. Just as long as they are consistently getting your main site links on peoples profiles thats our ultimate goal.</p> <p>You got to understand, this guy only has 344,000 links on profiles. Thats not a big deal. If his site has been up for the last two years thats only about 15,000/day, not counting a sharp increase from when he started ranking of course. Getting 15 subniche sites within your network getting about 1,000 uses/day isn&#8217;t too incredibly hard. You can get that within a month or two. Once you accomplish that, you are at least matching him which is progress in the right direction.</p> <p>Matching him? I&#8217;m sorry I fucked up. At that rate you&#8217;re no where NEAR matching him. There is the inevitable law of diminishing returns standing in your way. There are over 100 million Myspace profiles, only about 10 million exist in Google right now. Therefore less than 10% actually gets indexed. Since it&#8217;s only the ones that get indexed that matters to your rank than that means even if you match the 15,000/day; You&#8217;re really only getting 1,500 that matter. That&#8217;s not nearly enough. Consider your ass kicked. <img src='/wp-includes/images/smilies/icon_smile.gif' alt=':)' class='wp-smiley' />  Or is it? We may need the help of a good Ol&#8217; Blue Hat Technique to bridge the gap and turn that 10% into nearly 100%. The technique is called <strong>Log Link Matching</strong>. I&#8217;m not going to go into intricate detail about it until the post comes out of course, but I will hint to it and explain as it applies to this case.</p> <p><strong>Blue Hat Technique #XX - Log Link Matching</strong><br /> Anyone with experience can attest that not nearly all of the true links to your sites actually gets indexed and count in the search engines.  It&#8217;s unfortunate but true. Not every page is indexed by the engines such as Google and therefore even if they link to you, they can&#8217;t pass a value. This is especially true for social sites like Myspace where only about 10% of the profiles get indexed. Log Link Matching is a technique used to ensure that nearly 100% of your real inbound links gets actually indexed by the search engines, thus<br /> dramatically increasing your visible inbound links and bumping your rank in an indescribable way. Here&#8217;s how it works.</p> <p>First create an automated <a href="/power-indexing-tips/">Roll Over Site</a> using my <a href="/abandoned-wordpress-accounts-pt-2/">Abandoned Wordpress Accounts Part 2</a> post. Did I mention all my techniques merge together? Well they do. <img src='/wp-includes/images/smilies/icon_smile.gif' alt=':)' class='wp-smiley' />  Do this by first building up several Wordpress blogs into high PR blogs by doing the Digg.com method as described. This will get plenty of search engine spiders to the site on a steady and fast stream as well as give plenty of authority to the site(to boost each site). Lastly, make a system that allows you to quickly add links to your Blogrolls within these accounts (quit being lazy and learn how to code!).</p> <p>After you got your Wordpress.com blogs setup start parsing through your site&#8217;s log files. The log files are the first indicator of someone linking to your site. Everytime someone pulls an image on their Myspace account from your server it will show up in there, regardless of whether or not their profile actually shows up in the engines. Where there is a profile pulling your images there is more than likely a link to your site. So you must get that profile page indexed in the search engines in order for the link to count. So parse through your log file for any referrers coming from profile.myspace.com or www.myspace.com/*. Remember profile.myspace.com/viewprofile.blahblahblah?friendid=blahblah is a page on its own just like www.myspace.com/myusername. Therefore BOTH count. So there&#8217;s no reason why our site can&#8217;t instantly almost double all of his links from Myspace profiles at the exact same time as getting nearly 100% of them indexed. All he has to do is start adding each of these referrers to his blogrolls. After so many Wordpress.com will automatically limit how many links actually show up and start randomizing which ones are shown on each and every pageview(or spider view). I think that limit is 15 currently but I&#8217;m not entirely sure. It seems to change every so often. Either way every time Googlebot visits the rollover sites it&#8217;ll be greeted by XX amount of Myspace profiles to index. Eventually it&#8217;ll get almost all of them. Thus the illusion of our inbound links tripling and even quadrupling daily will start happening. We won&#8217;t actually be performing nearly to the degree it appears, but we definitely won&#8217;t be short any needed momentum either. It&#8217;ll just appear that way because many links we&#8217;ve had for a long time will finally start showing up and giving us proper credit.</p> <p>If we keep parsing the log files and checking for new people using our templates and ensuring they all get indexed eventually we will catch up to that #1 site. Coincide that with our link laundering sites within our network we should have no problem overtaking him and holding our ground. Once we are at that point, its check and mate for the time being. He&#8217;s either going to have to top that performance or back off and accept his second place trophy. If he does manage to pull something sneaky and come back, no big deal, persistence is worth more than gold.</p> <p><em>I hope this little real life example helped a few people in the same situation, and I&#8217;ll move up the date on that Blue Hat Log Link Matching Technique so you can get the details of it and really learn how to utilize it in some very powerful ways. It never hurts to have more in our arsenal. <img src='/wp-includes/images/smilies/icon_smile.gif' alt=':)' class='wp-smiley' />  Just remember, the fact that you already have more inbound links from other Myspace layout related sites than him. If you can just match him on his strong points you can beat him.</em></p> <p><strong>Go Get &#8216;Em Tiger!</strong> </p>  	<p class="post-info"> 													 	</p> 	<!-- 		<rdf:RDF xmlns:rdf="/web/20130510105514/http://www.w3.org/1999/02/22-rdf-syntax-ns#" 	    xmlns:dc="/web/20130510105514/http://purl.org/dc/elements/1.1/" 	    xmlns:trackback="/web/20130510105514/http://madskills.com/public/xml/rss/module/trackback/"> 		<rdf:Description rdf:about="/web/20130510105514/http://www.bluehatseo.com/real-seo-example/"     dc:identifier="/web/20130510105514/http://www.bluehatseo.com/real-seo-example/"     dc:title="Real SEO Example"     trackback:ping="/web/20130510105514/http://www.bluehatseo.com/real-seo-example/trackback/" /> </rdf:RDF>	--> </div> <div class="post-footer"><a href="/real-seo-example/#comments" title="Comment on Real SEO Example">187 Comments &#187;</a></div>									</div> 							 				<div class="post"> 					<div class="post-title"><em><a href="/category/general-articles/" title="View all posts in General Articles" rel="category tag">General Articles</a></em>27 Apr 2007 07:06 pm</div> <p class="post-info"><a href="/parabole-whitehat-vs-blackhat/" rel="bookmark" title="Permanent Link: The Parable Of The White Hat &#038; The Black Hat"><b>The Parable Of The White Hat &#038; The Black Hat</b></a></p> <div class="post-content" align="justified"> 	<p>When linking here, for some reason people keep describing this blog&#8217;s content as grey and black hat. I&#8217;m flattered but I actually couldn&#8217;t disagree more. If anything I&#8217;m trying to make some serious noise to the white hats and encouraging them to learn some new tricks, but most seem to be covering their ears with enthusiasm. La la la la I can&#8217;t hear you! On that note there&#8217;s an interesting long-term debate going on disputing whats better, black hat or white hat? Did I say interesting? I meant boring and completely bullshit. Saying you like black hat better doesn&#8217;t make you a black hat. Likewise, showing your disgust for black hats without learning it doesn&#8217;t even make you a white hat. In my opinion until you take the time to learn and develop both skills to the fullest extent there&#8217;s only one classification for you&#8230;.Amateur.</p> <p>So with that I&#8217;m going to attempt to make the ultimate white hat post by telling the ever famous parable of The White Hatter and The Black Hatter. You may have already heard it. If you&#8217;re not familiar, a parable is a short story, often fictional, told to illustrate a lesson or morale. If that still doesn&#8217;t ring any bells then you should read the Bible more you heathen. There are several in there. I&#8217;m kidding of course. I respect your religion now matter what it is. <img src='/wp-includes/images/smilies/icon_smile.gif' alt=':)' class='wp-smiley' />  and Yes, there will be real techniques you can use hidden within the story. <img src='/wp-includes/images/smilies/icon_smile.gif' alt=':)' class='wp-smiley' /> </p> <p><strong>The Black Hatter And The White Hatter - When Two Pros Meet</strong><br /> Once there was a white hatter. He had a great website that ranked #1 in a competitive niche. He had many fans of his site and it got lots of search engine traffic from his primary keyword. Suddenly one week while checking up on his site he noticed another high quality site in his niche moving up quickly in the ranks. It was also a very nice site with lots of value. The White Hatter didn&#8217;t think much of it because of his own solid rankings but knew he better watch this site more closely due to it&#8217;s upward momentum.  Suddenly one day after a small SERP update the site he was watching moved into the #2 slot right under him. This started to make him nervous because he knew the differences in income between the number one and number two slots. He has gotten very comfortable in the number one position and had no intentions of giving it up.</p> <p>Once there was a black hatter. He created a few Made For Adsense sites across a couple hundred niches. They were fairly uniform. Some performed well, some performed poorly. By chance of fate one of these sites was in the White Hat&#8217;s niche. Since this was a competitive niche his site quickly caught the attention of the lower positioned sites that were still struggling amongst themselves for the #2 slot. The black hatter&#8217;s site was doing fairly well in this niche and making a couple bucks a day. It wasn&#8217;t ranking for any major terms within the niche, but since the niche was such a good one it was still bringing him some solid residual and he was very happy. The rest of the site owners within the niche, angered by his intrusion, quickly took action against his black hat site. After a few legal threats and a bunch of complaints to everyone possible they were finally successful and got the black hatter&#8217;s site taken down and banned. Once entered and realizing the potential of the niche the Black Hatter reluctantly took the site down and built a clean site for competition within the niche. There&#8217;s no point in letting such a great niche go he thought. So he built a very clean and high quality site and aimed it directly at the most competitive keyword. He built up the site nicely and quickly. While the other lower sites within the niche fought amongst themselves and spent their time combating the endless supply of spam entering their niche he focused on building the link count required for the number one position. It wasn&#8217;t very long before he managed to grab the number 2 slot. Things were going well except that number one site in his way was clearly going to be a force to be reckoned with. He was going to have to pull off something slick.</p> <p>By this time the site had the full attention of the White Hatter. He started watching the inbound links and site content of the Black Hatter&#8217;s site intently. It seemed fairly even. In fact this site even managed to get many of the same link spots he had as well as a few new ones. The site had lost its momentum but still a worthy adversary for the top spot. The White Hatter watched in dismay as his site and the other bounced back and forth between the top two positions. He continued building links and working on his site. Suddenly without notice, the other site took the top position and it stuck. The opponent kept it and wasn&#8217;t budging. The White Hatter had to figure out why and quickly. Both sites had a solid number of links at about 45k-50k and almost all were at least relevant. He started investigating all the inbound links and finally one day found something very odd. This other site had about 10,000 new inbound links from random Blogspot accounts.</p> <p>The Black Hatter knew he wasn&#8217;t going to take down this monstrous number one site by playing clean. He had to do something drastic. So he whipped up some scripts and grabbed a list of the top 1,000 or so keywords for the niche and created some Blogspot accounts accordingly. He populated them from a popular RSS Aggregator and made sure each page had a link to his main money site. With the added link popularity he easily took the number one position and wasn&#8217;t budging. He didn&#8217;t want these Splogs to get quickly banned and knew later on he would need their link age so he did the responsible black hat thing and gave each post credit to the original and left all the ads out. He also knew not to continuously create too many and draw attention. He had to keep his numbers just high enough to gain and maintain his position and stop it there and just consistently update each blog once it&#8217;s established. After all the big money was in his big clean money site and he knew it.</p> <p>The White Hatter definitely received a big blow to his business and had no intentions of taking it lying down. He created a crawler and using the footprints within the Blogspot templates started compiling a list of all the accounts made. He located a large portion of the 10,000 accounts and started investigating where all their content was coming from. They were clearly feed scrapes. So he took all the post titles and scanned common RSS  Aggregators. He found it! They were coming from Google Blog Search. The White Hatter was smart. He knew if he started panicking and throwing a fit and trying to get Blogspot and the search engines to delete and ban all these accounts it would do him no good. The other site could easily generate them faster than he could ever get them deleted. It was clearly a futile effort and he knew it. Time for a workable plan. So he had to hit the Blogspot accounts where it hurts. He used his crawler to scrape all the titles of almost all the scraped posts created. The White Hatter then concocted a script to ping Google Blog search with all the same post titles as was in his list. He injected links to his site within the article content as well as put himself as the source. Unfortunately, the scraper was smart enough to remove all the html from the feeds but he still got to keep the original link within each and every post. He knew that if each of these post titles managed to get grabbed by the Black Hatters scraping script than they would surely get snagged again once all the blogs got updated and he fed them into the aggregator. It worked. All the new posts on all the spammy Blogspot accounts now had a link to his site. This evened the playing field. Whenever the Black Hatter&#8217;s site got a link, his site got a link. However this wasn&#8217;t acceptable, the black hat site still had all the previous post links and was barely beating him. Something had to get done about that. All these links had to be devalued. So the White Hatter opened up his Askimet filter logs and started scanning for domains that were banned in the engines. Once he managed to find a couple hundred so he started slowly feeding them to the Blogspot accounts through the Google Blog Search feed. He kept the same post titles knowing they would get scraped yet again and he made a balanced mixture of putting his site as the source of the post as well as the banned domains that way they would both get links.</p> <p>By this time the Black Hatter, with his position secure, had already moved on to his next niche. Suddenly one day he noticed a large drop in revenue. His site had lost the number one position and was back in the battle for the first two spots. &#8220;What the hell is going on?!&#8221; he thought. He looked at his Blogspot scripts to find the source of the problem. He quickly noticed that not only was his accounts giving his main competitor links but they weren&#8217;t worth a shit because he was also linking to a bunch of banned pharmaceutical sites, putting every Splog he created into bad neighborhoods. His efforts were worthless and he knew why and more importantly how. It was time to face a tough decision. He could either endlessly combat this guy, who obviously knew his stuff, to keep his current revenue or he could move on and continue to focus on new niches and creating new revenue for himself. He couldn&#8217;t help but laugh about it. So he emailed the White Hat and expressed his respect for the competitive exchange. There was no point in furthering it and they both decided to call it quits and just exchange links on the main page to help lock in their positions and let the algorithms decide from there who was better. After considering it a draw they both went their separate ways.</p> <p><strong>The Moral Of The Story</strong><br /> Interpret it however you want but recognize the fact that the White Hat defended himself. He didn&#8217;t just roll over or waste his time throwing a fit trying to get the inevitably endless supply of black hat sites banned or deleted. He knew his opponents tricks and thus was well equipped to combat them. He stood his moral stance and did what he had to, in order to protect his business. No matter where you stand on the issue you can respect that.</p> <p><em>If you hear anyone whining and crying about black hats or white hats please politely explain to them that there are no black or white hats. Only amateurs, experts, and people who are willing to learn how to protect and grow their businesses then send them this story. <img src='/wp-includes/images/smilies/icon_smile.gif' alt=':)' class='wp-smiley' />  </em> </p>  	<p class="post-info"> 													 	</p> 	<!-- 		<rdf:RDF xmlns:rdf="/web/20130510105514/http://www.w3.org/1999/02/22-rdf-syntax-ns#" 	    xmlns:dc="/web/20130510105514/http://purl.org/dc/elements/1.1/" 	    xmlns:trackback="/web/20130510105514/http://madskills.com/public/xml/rss/module/trackback/"> 		<rdf:Description rdf:about="/web/20130510105514/http://www.bluehatseo.com/parabole-whitehat-vs-blackhat/"     dc:identifier="/web/20130510105514/http://www.bluehatseo.com/parabole-whitehat-vs-blackhat/"     dc:title="The Parable Of The White Hat &#038; The Black Hat"     trackback:ping="/web/20130510105514/http://www.bluehatseo.com/parabole-whitehat-vs-blackhat/trackback/" /> </rdf:RDF>	--> </div> <div class="post-footer"><a href="/parabole-whitehat-vs-blackhat/#comments" title="Comment on The Parable Of The White Hat &#038; The Black Hat">175 Comments &#187;</a></div>									</div> 							 				<div class="post"> 					<div class="post-title"><em><a href="/category/general-articles/" title="View all posts in General Articles" rel="category tag">General Articles</a></em>24 Apr 2007 10:43 pm</div> <p class="post-info"><a href="/keyword-real-estate/" rel="bookmark" title="Permanent Link: Keyword Real Estate"><b>Keyword Real Estate</b></a></p> <div class="post-content" align="justified"> 	<p>Hey guys and gals. Incase you didn&#8217;t notice I took a short break from posting to catch up on some work. Thanks for hanging out. <img src='/wp-includes/images/smilies/icon_smile.gif' alt=':)' class='wp-smiley' />  Let&#8217;s review. In my <a href="/serp-domination/">SERP Domination</a> post I spilled the beans about creating a site network by breaking down a larger site to take down the competition in a very efficient manner. This of course works beautifully in reverse, but we&#8217;ll save that for another day. In the mean time though I want to touch on a small portion of that post I could of easily divulged a hell of a lot more on. I&#8217;m talking about the &#8220;secondary network.&#8221; Incase you have short term memory loss I&#8217;ll refresh ya with a quote from the post.</p> <p>[quote]Blah blah blah, sexist joke. Blah blah snarky remark. I&#8217;ll create a much larger secondary network to help boost my blah blah inbound link authority. Blah blah ramble ramble.[/quote]</p> <p>In words longer than short I introduced the well proven concept of Keyword Real Estate. Keyword Real Estate isn&#8217;t just a concept its a practice. In fact scratch that. Keyword Real Estate is the law of high rankings just as sure as Murphy&#8217;s law will make your servers go down between 1-3am instead of 9-5pm. Practicing good keyword real estate snatching will help boost your sites. I will go as far as to say that it is unwise to enter any niche no matter how uncompetitive without grabbing up as much real estate related to your terms as possible. I&#8217;ll explain.</p> <p>Domains, Free Hosting, Blog Networks, Social Networks, Social Bookmarking, URL Shorteners. The list goes on and on. Any where there is an authoritative domain that allows you to own a static page there is no reason why you shouldn&#8217;t register it and put up a landing page advertising your site(s), or even a simple link if that&#8217;s all that is possible. I&#8217;ll explain this in a simplistic white hat way using an analogy because this is in no gray or black hat about it, its just common sense business.</p> <p>Imagine you live in a big city and you setup a small business. The local phone book <strong>directories</strong> want you to pay them to put a small business card sized ad in the yellowpages/category/keyword/page/adspot. Okay so it fits within your ROI so you do it. It&#8217;s almost manditory for a small business to be found by it&#8217;s customers. However, at the same time, all over the city there are these giant sky scrapers with all these blank billboards on them. They are giving them out for free all you got to do is claim them first before your competitors do and you can put up any ad for your business you want within reason(<strong>TOS</strong>). Also, in other portions of this fictional city are little chunks of land that you can grab and put up a giant sign with a big ass arrow pointing to your business. They may not be in the primo business districts but they at least get drive by traffic. I don&#8217;t know about you but I&#8217;m too ethical of a business owner to take advantage. <img src='/wp-includes/images/smilies/icon_smile.gif' alt=':)' class='wp-smiley' /> </p> <p>Ya know on second thought, I think I will jump in on this offer. So let&#8217;s look at a few examples of these billboards and opportunities for Keyword Real Estate and where to easily find them. They are everywhere.</p> <p><strong>A few examples might include:</strong></p> <p>keyword.Wordpress.com<br /> keyword.blogspot.com<br /> keyword.blogger.com<br /> del.icio.us/keyword<br /> borntobuzz.com/keyword<br /> digg.com/users/keyword<br /> technorati.com/profile/keyword<br /> bloglines.com/blog/keyword<br /> keyword.typepad.com<br /> astore.amazon.com/keyword-20<br /> myspace.com/keyword<br /> squidoo.com/keyword<br /> keyword.spaces.live.com<br /> someforum.com/members/keyword.html <-<em>vbulletin with vbseo installed &#038; your link in the signature.</em><br /> I know it&#8217;s simple and not very advanced advice, but it&#8217;s solid.  Look at what the experts are doing. A great example of how well this works is of course SEO Contests. How are they won? In the simple sense they are won by Keyword Real Estate. They are also a great resource for finding some awesome opportunities. After all it works damn well. I personally never enter a competitive niche without grabbing as much real estate as possible on that keyword or phrase and using it to boost my sites&#8217; rankings and traffic. It&#8217;s common sense, all you got to do is follow through religiously. </p>  	<p class="post-info"> 													 	</p> 	<!-- 		<rdf:RDF xmlns:rdf="/web/20130510105514/http://www.w3.org/1999/02/22-rdf-syntax-ns#" 	    xmlns:dc="/web/20130510105514/http://purl.org/dc/elements/1.1/" 	    xmlns:trackback="/web/20130510105514/http://madskills.com/public/xml/rss/module/trackback/"> 		<rdf:Description rdf:about="/web/20130510105514/http://www.bluehatseo.com/keyword-real-estate/"     dc:identifier="/web/20130510105514/http://www.bluehatseo.com/keyword-real-estate/"     dc:title="Keyword Real Estate"     trackback:ping="/web/20130510105514/http://www.bluehatseo.com/keyword-real-estate/trackback/" /> </rdf:RDF>	--> </div> <div class="post-footer"><a href="/keyword-real-estate/#comments" title="Comment on Keyword Real Estate">307 Comments &#187;</a></div>									</div> 						<p align="center"> &#8212; <a href="/category/general-articles/page/2/">Next Page &raquo;</a></p>		 					 	</div> 	<div id="sidebar">		 		<li class="pagenav"><h2>Pages</h2><ul><li class="page_item"><a href="/contribute/" title="Contribute">Contribute</a></li> <li class="page_item"><a href="/have-a-question/" title="Have A Question?">Have A Question?</a></li> <li class="page_item"><a href="/what-is-blue-hat-seo/" title="What Is Blue Hat SEO?">What Is Blue Hat SEO?</a></li> </ul></li> <h2>Categories:</h2> 	<ul>	<li class="current-cat"><a href="/category/general-articles/" title="View all posts filed under General Articles">General Articles</a> (55) </li> 	<li><a href="/category/blue-hat-techniques/" title="View all posts filed under Blue Hat Techniques">Blue Hat Techniques</a> (21) </li> 	<li><a href="/category/random-thoughts/" title="View all posts filed under Random Thoughts">Random Thoughts</a> (42) </li> 	<li><a href="/category/site-reviews-commentary/" title="View all posts filed under Site Reviews &#038; Commentary">Site Reviews &#038; Commentary</a> (8) </li> 	<li><a href="/category/seo-tools/" title="View all posts filed under SEO Tools">SEO Tools</a> (9) </li> 	<li><a href="/category/announcements/" title="View all posts filed under Announcements">Announcements</a> (17) </li> 	<li><a href="/category/update-reports/" title="View all posts filed under Update Reports">Update Reports</a> (2) </li> 	<li><a href="/category/neat-tricks-and-hacks/" title="View all posts filed under Neat Tricks and Hacks">Neat Tricks and Hacks</a> (19) </li> 	<li><a href="/category/guides/" title="View all posts filed under Guides">Guides</a> (5) </li> 	<li><a href="/category/user-contributed/" title="View all posts filed under User Contributed">User Contributed</a> (9) </li> 	<li><a href="/category/check-mates/" title="View all posts filed under Check Mates">Check Mates</a> (4) </li> 	<li><a href="/category/black-hole-seo/" title="View all posts filed under Black Hole SEO">Black Hole SEO</a> (4) </li> </ul>  <h2><label for="s">Search:</label></h2> 	<ul> 		<li> 			<form id="searchform" method="get" action="/web/20130510105514/http://www.bluehatseo.com/index.php"> 				<div> 					<p><input type="text" name="s" id="s" size="15" /></p> 					<p><input type="submit" name="submit" value="Search" /></p> 				</div> 			</form> 		</li> 	</ul> <h2>Monthly:</h2> 	<ul>	<li><a href='/2011/06/' title='June 2011'>June 2011</a>&nbsp;(1)</li> 	<li><a href='/2010/07/' title='July 2010'>July 2010</a>&nbsp;(2)</li> 	<li><a href='/2010/06/' title='June 2010'>June 2010</a>&nbsp;(1)</li> 	<li><a href='/2009/11/' title='November 2009'>November 2009</a>&nbsp;(2)</li> 	<li><a href='/2009/09/' title='September 2009'>September 2009</a>&nbsp;(1)</li> 	<li><a href='/2009/06/' title='June 2009'>June 2009</a>&nbsp;(2)</li> 	<li><a href='/2009/04/' title='April 2009'>April 2009</a>&nbsp;(1)</li> 	<li><a href='/2009/02/' title='February 2009'>February 2009</a>&nbsp;(1)</li> 	<li><a href='/2008/11/' title='November 2008'>November 2008</a>&nbsp;(1)</li> 	<li><a href='/2008/09/' title='September 2008'>September 2008</a>&nbsp;(1)</li> 	<li><a href='/2008/08/' title='August 2008'>August 2008</a>&nbsp;(1)</li> 	<li><a href='/2008/07/' title='July 2008'>July 2008</a>&nbsp;(2)</li> 	<li><a href='/2008/05/' title='May 2008'>May 2008</a>&nbsp;(2)</li> 	<li><a href='/2008/03/' title='March 2008'>March 2008</a>&nbsp;(3)</li> 	<li><a href='/2007/12/' title='December 2007'>December 2007</a>&nbsp;(5)</li> 	<li><a href='/2007/10/' title='October 2007'>October 2007</a>&nbsp;(2)</li> 	<li><a href='/2007/09/' title='September 2007'>September 2007</a>&nbsp;(1)</li> 	<li><a href='/2007/08/' title='August 2007'>August 2007</a>&nbsp;(1)</li> 	<li><a href='/2007/07/' title='July 2007'>July 2007</a>&nbsp;(3)</li> 	<li><a href='/2007/06/' title='June 2007'>June 2007</a>&nbsp;(8)</li> 	<li><a href='/2007/05/' title='May 2007'>May 2007</a>&nbsp;(4)</li> 	<li><a href='/2007/04/' title='April 2007'>April 2007</a>&nbsp;(8)</li> 	<li><a href='/2007/03/' title='March 2007'>March 2007</a>&nbsp;(4)</li> 	<li><a href='/2007/02/' title='February 2007'>February 2007</a>&nbsp;(3)</li> 	<li><a href='/2007/01/' title='January 2007'>January 2007</a>&nbsp;(6)</li> 	<li><a href='/2006/12/' title='December 2006'>December 2006</a>&nbsp;(8)</li> 	<li><a href='/2006/11/' title='November 2006'>November 2006</a>&nbsp;(12)</li> 	<li><a href='/2006/10/' title='October 2006'>October 2006</a>&nbsp;(13)</li> 	<li><a href='/2006/09/' title='September 2006'>September 2006</a>&nbsp;(5)</li> 	<li><a href='/2006/08/' title='August 2006'>August 2006</a>&nbsp;(10)</li> 	<li><a href='/2006/07/' title='July 2006'>July 2006</a>&nbsp;(12)</li> 	<li><a href='/2006/06/' title='June 2006'>June 2006</a>&nbsp;(4)</li> 	<li><a href='/2006/05/' title='May 2006'>May 2006</a>&nbsp;(4)</li> 	<li><a href='/2006/04/' title='April 2006'>April 2006</a>&nbsp;(15)</li> 	<li><a href='/2006/03/' title='March 2006'>March 2006</a>&nbsp;(14)</li> 	<li><a href='/2006/02/' title='February 2006'>February 2006</a>&nbsp;(15)</li> 	<li><a href='/2006/01/' title='January 2006'>January 2006</a>&nbsp;(15)</li> </ul>  <h2>RSS Feeds:</h2> 	<ul> 		<li><a href="http://feeds.feedburner.com/BlueHatSEO/HXKR" title="Subscribe to my feed" rel="alternate" type="application/rss+xml"></a><a href="http://feeds.feedburner.com/BlueHatSEO/HXKR" title="Subscribe to my feed" rel="alternate" type="application/rss+xml">Subscribe in a reader</a> 			<a title="RSS2 Feed for Posts" href="/feed/">Posts</a> | <a title="RSS2 Feed for Comments" href="/comments/feed/">Comments</a></li>	 	</ul>	 <li> <h2>Recent Comments</h2> <ul><li><strong>Margahayuland:</strong> <a href="/seo-empire-part-1/#comment-622887" title="View the entire comment by Margahayuland">I like the information on this website is mainly for...</a></li><li><strong>Aniexty:</strong> <a href="/advanced-white-hat-seo-exists-damn-it-dynamic-seo/#comment-622882" title="View the entire comment by Aniexty">Wow nice information you have here.Thanks for sharing Interesting blog....</a></li><li><strong>Aniexty:</strong> <a href="/open-questions-subdomains-and-main-domains/#comment-622881" title="View the entire comment by Aniexty">I am happy to find your distinguished way of writing...</a></li><li><strong>Aniexty:</strong> <a href="/conspiracy-theories-please/#comment-622880" title="View the entire comment by Aniexty">It is a referendum on a culture of secret dealings...</a></li><li><strong>Aniexty:</strong> <a href="/review-of-autopligg-backlink-tool/#comment-622879" title="View the entire comment by Aniexty">Good read, I just passed this onto a colleague who...</a></li><li><strong>Fulcrum Media Limited:</strong> <a href="/advanced-white-hat-seo-exists-damn-it-dynamic-seo/#comment-622878" title="View the entire comment by Fulcrum Media Limited">Very interesting article - have you heard of some software...</a></li><li><strong>Aniexty:</strong> <a href="/blue-hat-technique-21-advanced-mininet-building/#comment-622877" title="View the entire comment by Aniexty">So informative things are provided here, I really happy to...</a></li><li><strong>Aniexty:</strong> <a href="/addon-domain-spamming-with-wordpress-and-any-other-cms/#comment-622876" title="View the entire comment by Aniexty">I will forward this post to him. Pretty sure he...</a></li><li><strong>Aniexty:</strong> <a href="/how-to-take-down-a-competitors-website-legally/#comment-622875" title="View the entire comment by Aniexty">Could not be written any better. Reading this post reminds...</a></li><li><strong>Aniexty:</strong> <a href="/open-questions-when-to-never-do-article-submissions/#comment-622873" title="View the entire comment by Aniexty">Your post is very nice.i like your thinking very much.i...</a></li></ul> </li> <li> <h2>Top Commentators</h2> <ul><li><a href='http://www.discussweightloss.com'>Weight Loss</a> (131) </li> <li><a href='http://sayyesyoga.com'>Yoga</a> (121) </li> <li><a href='http://www.visiblexposure.com'>visiblexposure.com</a> (118) </li> <li><a href='http://www.celebritiesjewellery.com'>Jewellery</a> (113) </li> <li><a href='http://www.goanxietyfree.com'>Aniexty</a> (109) </li> <li><a href='http://www.planetofphotography.com'>Planet of Photography</a> (97) </li> <li><a href='http://vindicatemj.wordpress.com'>Vindicatemj</a> (94) </li> <li><a href='http://technocrathub.com'>Technocrathub</a> (91) </li> <li><a href='http://propertymarbellaapartments.com'>Property Marbella</a> (87) </li> <li><a href='http://flavaflav.atspace.co.uk'>Lee</a> (82) </li> </ul> </li> 	</div> <p id="footer">  <small>Template by <a href="http://www.myspaceimagecodes.net">Myspace Image Codes</a> available at <a href="http://www.moshable.com">Free Music</a>. Check Out My Other Site <a href="http://www.mp3search.fm">MP3 Search</a>  Credit to </a>.</small>  </div>  </body> </html>     <!--       10:55:14 May 10, 2013        21:27:06 Jan 26, 2017.                    --> 